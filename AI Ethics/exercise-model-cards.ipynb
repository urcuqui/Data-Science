{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"papermill":{"default_parameters":{},"duration":22.765098,"end_time":"2021-02-27T00:54:36.925324","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2021-02-27T00:54:14.160226","version":"2.2.2"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"**This notebook is an exercise in the [AI Ethics](https://www.kaggle.com/learn/ai-ethics) course.  You can reference the tutorial at [this link](https://www.kaggle.com/var0101/model-cards).**\n\n---\n","metadata":{}},{"cell_type":"markdown","source":"In the tutorial, you learned how to use model cards.  In this exercise, you'll sharpen your understanding of model cards by engaging with them in a couple of scenarios.\n\n# Introduction\n\nRun the next code cell to get started.","metadata":{"papermill":{"duration":0.010515,"end_time":"2021-02-27T00:54:36.124158","exception":false,"start_time":"2021-02-27T00:54:36.113643","status":"completed"},"tags":[]}},{"cell_type":"code","source":"from learntools.core import binder\nbinder.bind(globals())\nfrom learntools.ethics.ex5 import *","metadata":{"papermill":{"duration":0.022761,"end_time":"2021-02-27T00:54:36.157779","exception":false,"start_time":"2021-02-27T00:54:36.135018","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-07-02T15:34:28.215352Z","iopub.execute_input":"2023-07-02T15:34:28.215726Z","iopub.status.idle":"2023-07-02T15:34:28.281860Z","shell.execute_reply.started":"2023-07-02T15:34:28.215695Z","shell.execute_reply":"2023-07-02T15:34:28.280891Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"# Scenario A\n\nYou are the creator of the _Simple Zoom_ video editing tool, which uses AI to automatically zoom the video camera in on a presenter as they walk across a room during a presentation. You are launching the _Simple Zoom_ tool and releasing a model card along with the tool, in the interest of transparency.\n\n# 1) Audience\n\nWhich audiences should you write the model card for? Once you have thought about your answer, check it against the solution below. ","metadata":{"papermill":{"duration":0.010424,"end_time":"2021-02-27T00:54:36.178986","exception":false,"start_time":"2021-02-27T00:54:36.168562","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# Check your answer (Run this code cell to receive credit!)\nq_1.check()","metadata":{"papermill":{"duration":0.022406,"end_time":"2021-02-27T00:54:36.212336","exception":false,"start_time":"2021-02-27T00:54:36.18993","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-07-02T15:35:40.761732Z","iopub.execute_input":"2023-07-02T15:35:40.762121Z","iopub.status.idle":"2023-07-02T15:35:40.774503Z","shell.execute_reply.started":"2023-07-02T15:35:40.762068Z","shell.execute_reply":"2023-07-02T15:35:40.773172Z"},"trusted":true},"execution_count":2,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Javascript object>","application/javascript":"parent.postMessage({\"jupyterEvent\": \"custom.exercise_interaction\", \"data\": {\"outcomeType\": 1, \"valueTowardsCompletion\": 0.3333333333333333, \"interactionType\": 1, \"questionType\": 4, \"questionId\": \"1_ScenarioA\", \"learnToolsVersion\": \"0.3.4\", \"failureMessage\": \"\", \"exceptionClass\": \"\", \"trace\": \"\"}}, \"*\")"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Solution: Model cards should be written for the groups that are most likely to read it. For *Simple Zoom*, such groups probably include people using the tool to record videos, organizations seeking to adopt the tool, IT and audio-visual teams and agencies, computer vision researchers, policymakers and developers of similar AI systems. Given how broad this group is, your team can only assume a basic knowledge of video recording terms throughout the model card.","text/markdown":"<span style=\"color:#33cc33\">Solution:</span> Model cards should be written for the groups that are most likely to read it. For *Simple Zoom*, such groups probably include people using the tool to record videos, organizations seeking to adopt the tool, IT and audio-visual teams and agencies, computer vision researchers, policymakers and developers of similar AI systems. Given how broad this group is, your team can only assume a basic knowledge of video recording terms throughout the model card."},"metadata":{}}]},{"cell_type":"markdown","source":"# Scenario B\n\nYou are the product manager for _Presenter Pro_, a popular video and audio recording product for people delivering talks and presentations. As a new feature based on customer demand, your team has been planning to add the AI-powered ability for a single video camera to automatically track a presenter, focusing on them as they walk across the room or stage, zooming in and out automatically and continuously adjusting lighting and focus within the video frame. \n\nYou are hoping to incorporate a different company’s AI tool (called _Simple Zoom_) into your product (_Presenter Pro_). To determine whether _Simple Zoom_ is a good fit for _Presenter Pro_, you are reviewing *Simple Zoom*’s model card.\n\n# 2) Intended Use\n\nThe **Intended Use** section of the model card includes the following bullets:\n* _Simple Zoom_ is intended to be used for automatic zoom, focus, and lighting adjustment in the real-time video recording of individual presenters by a single camera\n* _Simple Zoom_ is not suitable for presentations in which there is more than one presenter or for presentations in which the presenter is partially or fully hidden at any time\n\nAs a member of the team evaluating _Simple Zoom_ for potential integration into _Presenter Pro_, you are aware that _Presenter Pro_ only supports one presenter per video.\n\nHowever, you are also aware that in some _Presenter Pro_ customers use large props in their presentation videos. Given the information in the Intended Use section of the model card, what problem do you foresee for these customers if you integrate _Simple Zoom_ into _Presenter Pro_? What are some ways in which you could address this issue?","metadata":{"papermill":{"duration":0.011583,"end_time":"2021-02-27T00:54:36.235319","exception":false,"start_time":"2021-02-27T00:54:36.223736","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# Run this code cell to receive a hint\nq_2.hint()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Check your answer (Run this code cell to receive credit!)\nq_2.check()","metadata":{"papermill":{"duration":0.020576,"end_time":"2021-02-27T00:54:36.266949","exception":false,"start_time":"2021-02-27T00:54:36.246373","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-07-02T16:12:17.282710Z","iopub.execute_input":"2023-07-02T16:12:17.283151Z","iopub.status.idle":"2023-07-02T16:12:17.292141Z","shell.execute_reply.started":"2023-07-02T16:12:17.283095Z","shell.execute_reply":"2023-07-02T16:12:17.290960Z"},"trusted":true},"execution_count":3,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Javascript object>","application/javascript":"parent.postMessage({\"jupyterEvent\": \"custom.exercise_interaction\", \"data\": {\"outcomeType\": 1, \"valueTowardsCompletion\": 0.3333333333333333, \"interactionType\": 1, \"questionType\": 4, \"questionId\": \"2_ScenarioB\", \"learnToolsVersion\": \"0.3.4\", \"failureMessage\": \"\", \"exceptionClass\": \"\", \"trace\": \"\"}}, \"*\")"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Solution: Since *Simple Zoom* is not suitable for presentations in which the presenter is partially or fully hidden at any time, it might not work well in a presentation in which the presenter uses a large object, because the object could partially or fully hide the presenter. There are many potential ways to address this issue. For example, your team could reach out to the *Simple Zoom* team to assess the potential risks and harms of using *Simple Zoom* with props. As another example, your team could eventually add a message in the Presenter Pro user interface explaining that the *Simple Zoom* feature should not be used in presentations that use props.","text/markdown":"<span style=\"color:#33cc33\">Solution:</span> Since *Simple Zoom* is not suitable for presentations in which the presenter is partially or fully hidden at any time, it might not work well in a presentation in which the presenter uses a large object, because the object could partially or fully hide the presenter. There are many potential ways to address this issue. For example, your team could reach out to the *Simple Zoom* team to assess the potential risks and harms of using *Simple Zoom* with props. As another example, your team could eventually add a message in the Presenter Pro user interface explaining that the *Simple Zoom* feature should not be used in presentations that use props."},"metadata":{}}]},{"cell_type":"markdown","source":"# 3) Factors, Evaluation Data, Metrics, and Quantitative Analyses\n\nWe'll continue with **Scenario B**, where you are the product manager for _Presenter Pro_.  Four more sections of the model card for _Simple Zoom_ are described below.\n\n**Factors**: The model card lists the following factors as potentially relevant to model performance: \n* Group Factors\n  * Self-reported gender\n  * Skin tone\n  * Self-reported age\n* Other Factors\n  * Camera angle\n  * Presenter distance from camera\n  * Camera type\n  * Lighting\n\n**Evaluation Data**: To generate the performance metrics reported in the **Quantitative Analysis** section (discussed below), the _Simple Zoom_ team used an evaluation data set of 500 presentation videos, each between two and five minutes long. The videos included both regular and unusual presentation and recording scenarios and included presenters from various demographic backgrounds.\n\n**Metrics**: Since _Simple Zoom_ model performance is subjective (involving questions like whether a zoom is of appropriate speed or smoothness; or whether a lighting adjustment is well-executed), the _Simple Zoom_ team tested the tool’s performance by asking a diverse viewer group to view _Simple Zoom_’s output videos (using the evaluation dataset’s 500 videos as inputs). Each viewer was asked to rate the quality of video editing for each video on a scale of 1 to 10, and each video’s average rating was used as a proxy for _Simple Zoom_’s performance on that video.\n\n**Quantitative Analyses**: The quantitative analyses section of the model card includes a brief summary of performance results. According to the summary, the model generally performs equally well across all the listed demographic groups (gender, skin tone and age).\n\nThe quantitative analyses section also includes interactive graphs, which allow you to view the performance of the _Simple Zoom_ tool by each factor and by intersections of ‘Group’ and ‘Other’ factors.\n\nAs a member of the team evaluating _Simple Zoom_ for potential integration into _Presenter Pro_, what are some questions you might be interested in answering and exploring via the interactive graphs?","metadata":{"papermill":{"duration":0.011538,"end_time":"2021-02-27T00:54:36.290935","exception":false,"start_time":"2021-02-27T00:54:36.279397","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# Check your answer (Run this code cell to receive credit!)\nq_3.check()","metadata":{"papermill":{"duration":0.047767,"end_time":"2021-02-27T00:54:36.350911","exception":false,"start_time":"2021-02-27T00:54:36.303144","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-07-02T16:16:17.977916Z","iopub.execute_input":"2023-07-02T16:16:17.978334Z","iopub.status.idle":"2023-07-02T16:16:17.986834Z","shell.execute_reply.started":"2023-07-02T16:16:17.978302Z","shell.execute_reply":"2023-07-02T16:16:17.985874Z"},"trusted":true},"execution_count":4,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Javascript object>","application/javascript":"parent.postMessage({\"jupyterEvent\": \"custom.exercise_interaction\", \"data\": {\"outcomeType\": 1, \"valueTowardsCompletion\": 0.3333333333333333, \"interactionType\": 1, \"questionType\": 4, \"questionId\": \"3_ScenarioB2\", \"learnToolsVersion\": \"0.3.4\", \"failureMessage\": \"\", \"exceptionClass\": \"\", \"trace\": \"\"}}, \"*\")"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Solution: There are many possible answers to this question. For example, you may want to check that the model’s equal performance across demographic groups (gender, skin tone and age) remains equal across different camera angles, distances from camera, camera types and lighting conditions. As another example, you may want to know how well the model performs from the specific camera angles that _Production Pro_ customers most commonly use.","text/markdown":"<span style=\"color:#33cc33\">Solution:</span> There are many possible answers to this question. For example, you may want to check that the model’s equal performance across demographic groups (gender, skin tone and age) remains equal across different camera angles, distances from camera, camera types and lighting conditions. As another example, you may want to know how well the model performs from the specific camera angles that _Production Pro_ customers most commonly use."},"metadata":{}}]},{"cell_type":"markdown","source":"# Conclusion\n\nCongratulations!  You have reached the end of the AI Ethics course.  Once you have viewed all of the tutorials and successfully answered the questions in the exercises, you will receive a completion certificate to celebrate your hard work.  \n\nIf you enjoyed the AI Ethics course, we recommend the [**Machine Learning Explainability**](https://www.kaggle.com/learn/machine-learning-explainability) course as a next step.  To prepare for the content in this course, you should have some background in python (which you can get from the [**Python**](https://www.kaggle.com/learn/python) course) and machine learning (which you can get from the [**Intro to Machine Learning**](https://www.kaggle.com/learn/intro-to-machine-learning) course).","metadata":{"papermill":{"duration":0.01278,"end_time":"2021-02-27T00:54:36.378269","exception":false,"start_time":"2021-02-27T00:54:36.365489","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"---\n\n\n\n\n*Have questions or comments? Visit the [course discussion forum](https://www.kaggle.com/learn/ai-ethics/discussion) to chat with other learners.*","metadata":{}}]}