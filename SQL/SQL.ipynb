{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "declared-combine",
   "metadata": {},
   "source": [
    "The next material was taken from Kaggle. All credits are for the original authors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "configured-thesis",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "SELECT COUNT(ID)\n",
    "FROM table.pets\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "silent-booth",
   "metadata": {},
   "source": [
    "AVG() SUM() MIN() MAX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "demographic-attendance",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "SELECT Animal, COUNT(ID)\n",
    "FROM table.pets\n",
    "GROUP BY Animal\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "architectural-oxygen",
   "metadata": {},
   "source": [
    "*aggregate functionS*\n",
    "\n",
    "**Having** is used in combination with **GROUP BY** to ignore groups that do not meet certain criteria.\n",
    "\n",
    "For example the next query will only include groups that have more than one ID in them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "digital-trance",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "SELECT Animal, COUNT(ID)\n",
    "FROM table.pets\n",
    "GROUP BY Animal\n",
    "HAVING COUNT(ID) > 1\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "instructional-minister",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting google-cloud-datastore\n",
      "  Downloading google_cloud_datastore-2.1.6-py2.py3-none-any.whl (127 kB)\n",
      "Collecting proto-plus>=1.4.0\n",
      "  Downloading proto_plus-1.19.0-py3-none-any.whl (42 kB)\n",
      "Collecting google-cloud-core<3.0.0dev,>=1.4.0\n",
      "  Downloading google_cloud_core-2.0.0-py2.py3-none-any.whl (27 kB)\n",
      "Collecting google-api-core[grpc]<3.0.0dev,>=1.22.2\n",
      "  Downloading google_api_core-2.0.1-py2.py3-none-any.whl (92 kB)\n",
      "Collecting libcst>=0.2.5\n",
      "  Downloading libcst-0.3.21-py3-none-any.whl (514 kB)\n",
      "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from google-api-core[grpc]<3.0.0dev,>=1.22.2->google-cloud-datastore) (2.25.1)\n",
      "Collecting googleapis-common-protos<2.0dev,>=1.6.0\n",
      "  Using cached googleapis_common_protos-1.53.0-py2.py3-none-any.whl (198 kB)\n",
      "Requirement already satisfied: setuptools>=40.3.0 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from google-api-core[grpc]<3.0.0dev,>=1.22.2->google-cloud-datastore) (52.0.0.post20210125)\n",
      "Requirement already satisfied: google-auth<3.0dev,>=1.25.0 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from google-api-core[grpc]<3.0.0dev,>=1.22.2->google-cloud-datastore) (1.27.0)\n",
      "Requirement already satisfied: protobuf>=3.12.0 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from google-api-core[grpc]<3.0.0dev,>=1.22.2->google-cloud-datastore) (3.14.0)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from google-api-core[grpc]<3.0.0dev,>=1.22.2->google-cloud-datastore) (1.36.0)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from google-auth<3.0dev,>=1.25.0->google-api-core[grpc]<3.0.0dev,>=1.22.2->google-cloud-datastore) (4.2.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from google-auth<3.0dev,>=1.25.0->google-api-core[grpc]<3.0.0dev,>=1.22.2->google-cloud-datastore) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from google-auth<3.0dev,>=1.25.0->google-api-core[grpc]<3.0.0dev,>=1.22.2->google-cloud-datastore) (4.7.2)\n",
      "Requirement already satisfied: six>=1.9.0 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from google-auth<3.0dev,>=1.25.0->google-api-core[grpc]<3.0.0dev,>=1.22.2->google-cloud-datastore) (1.15.0)\n",
      "Requirement already satisfied: pyyaml>=5.2 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from libcst>=0.2.5->google-cloud-datastore) (5.4.1)\n",
      "Collecting typing-inspect>=0.4.0\n",
      "  Downloading typing_inspect-0.7.1-py3-none-any.whl (8.4 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.2 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from libcst>=0.2.5->google-cloud-datastore) (3.7.4.3)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3.0dev,>=1.25.0->google-api-core[grpc]<3.0.0dev,>=1.22.2->google-cloud-datastore) (0.4.8)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]<3.0.0dev,>=1.22.2->google-cloud-datastore) (2.10)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]<3.0.0dev,>=1.22.2->google-cloud-datastore) (3.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]<3.0.0dev,>=1.22.2->google-cloud-datastore) (1.26.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]<3.0.0dev,>=1.22.2->google-cloud-datastore) (2021.5.30)\n",
      "Collecting mypy-extensions>=0.3.0\n",
      "  Downloading mypy_extensions-0.4.3-py2.py3-none-any.whl (4.5 kB)\n",
      "Installing collected packages: mypy-extensions, googleapis-common-protos, typing-inspect, google-api-core, proto-plus, libcst, google-cloud-core, google-cloud-datastore\n",
      "Successfully installed google-api-core-2.0.1 google-cloud-core-2.0.0 google-cloud-datastore-2.1.6 googleapis-common-protos-1.53.0 libcst-0.3.21 mypy-extensions-0.4.3 proto-plus-1.19.0 typing-inspect-0.7.1\n"
     ]
    }
   ],
   "source": [
    "!pip install google-cloud-datastore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "guilty-agency",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting google-cloud-bigquery\n",
      "  Downloading google_cloud_bigquery-2.26.0-py2.py3-none-any.whl (201 kB)\n",
      "Requirement already satisfied: google-api-core[grpc]<3.0.0dev,>=1.29.0 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from google-cloud-bigquery) (2.0.1)\n",
      "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from google-cloud-bigquery) (2.25.1)\n",
      "Requirement already satisfied: proto-plus>=1.10.0 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from google-cloud-bigquery) (1.19.0)\n",
      "Requirement already satisfied: packaging>=14.3 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from google-cloud-bigquery) (20.9)\n",
      "Collecting google-resumable-media<3.0dev,>=0.6.0\n",
      "  Downloading google_resumable_media-2.0.3-py2.py3-none-any.whl (75 kB)\n",
      "Collecting grpcio<2.0dev,>=1.38.1\n",
      "  Downloading grpcio-1.40.0-cp37-cp37m-win_amd64.whl (3.2 MB)\n",
      "Requirement already satisfied: google-cloud-core<3.0.0dev,>=1.4.1 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from google-cloud-bigquery) (2.0.0)\n",
      "Requirement already satisfied: protobuf>=3.12.0 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from google-cloud-bigquery) (3.14.0)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from google-api-core[grpc]<3.0.0dev,>=1.29.0->google-cloud-bigquery) (1.53.0)\n",
      "Requirement already satisfied: google-auth<3.0dev,>=1.25.0 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from google-api-core[grpc]<3.0.0dev,>=1.29.0->google-cloud-bigquery) (1.27.0)\n",
      "Requirement already satisfied: setuptools>=40.3.0 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from google-api-core[grpc]<3.0.0dev,>=1.29.0->google-cloud-bigquery) (52.0.0.post20210125)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from google-auth<3.0dev,>=1.25.0->google-api-core[grpc]<3.0.0dev,>=1.29.0->google-cloud-bigquery) (4.7.2)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from google-auth<3.0dev,>=1.25.0->google-api-core[grpc]<3.0.0dev,>=1.29.0->google-cloud-bigquery) (4.2.1)\n",
      "Requirement already satisfied: six>=1.9.0 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from google-auth<3.0dev,>=1.25.0->google-api-core[grpc]<3.0.0dev,>=1.29.0->google-cloud-bigquery) (1.15.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from google-auth<3.0dev,>=1.25.0->google-api-core[grpc]<3.0.0dev,>=1.29.0->google-cloud-bigquery) (0.2.8)\n",
      "Collecting google-crc32c<2.0dev,>=1.0\n",
      "  Downloading google_crc32c-1.2.0-cp37-cp37m-win_amd64.whl (27 kB)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from packaging>=14.3->google-cloud-bigquery) (2.4.7)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3.0dev,>=1.25.0->google-api-core[grpc]<3.0.0dev,>=1.29.0->google-cloud-bigquery) (0.4.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-bigquery) (1.26.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-bigquery) (2021.5.30)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-bigquery) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-bigquery) (2.10)\n",
      "Installing collected packages: grpcio, google-crc32c, google-resumable-media, google-cloud-bigquery\n",
      "  Attempting uninstall: grpcio\n",
      "    Found existing installation: grpcio 1.36.0\n",
      "    Uninstalling grpcio-1.36.0:\n",
      "      Successfully uninstalled grpcio-1.36.0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorflow 2.1.0 requires scipy==1.4.1; python_version >= \"3\", but you have scipy 1.6.1 which is incompatible.\n",
      "tensorflow 2.1.0 requires tensorboard<2.2.0,>=2.1.0, but you have tensorboard 2.3.0 which is incompatible.\n",
      "econml 0.7.0 requires scikit-learn~=0.21.0, but you have scikit-learn 0.24.1 which is incompatible.\n",
      "econml 0.7.0 requires tensorflow==1.*, but you have tensorflow 2.1.0 which is incompatible.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Successfully installed google-cloud-bigquery-2.26.0 google-crc32c-1.2.0 google-resumable-media-2.0.3 grpcio-1.40.0\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade google-cloud-bigquery"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fuzzy-robert",
   "metadata": {},
   "source": [
    "If you are ever ensure what to put inside COUNT() function, you can do COUNT(1) to count the rows in each group. Less data quota using a cloud provider."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afraid-usage",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "SELECT parent, COUNT(1) AS NumPosts\n",
    "FROM comments\n",
    "GROUP BY parent\n",
    "HAVING COUNT(1) > 10\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "graduate-vegetation",
   "metadata": {},
   "source": [
    "IF YOU HAVE ANY **GROUP BY** CLAUSE, then all variables must be passed to either a without an aggregate function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "disabled-stephen",
   "metadata": {},
   "source": [
    "# Exercises\n",
    "\n",
    "### 1) Prolific commenters\n",
    "\n",
    "Hacker News would like to send awards to everyone who has written more than 10,000 posts. Write a query that returns all authors with more than 10,000 posts as well as their post counts. Call the column with post counts `NumPosts`.\n",
    "\n",
    "In case sample query is helpful, here is a query you saw in the tutorial to answer a similar question:\n",
    "```\n",
    "query = \"\"\"\n",
    "        SELECT parent, COUNT(1) AS NumPosts\n",
    "        FROM `bigquery-public-data.hacker_news.comments`\n",
    "        GROUP BY parent\n",
    "        HAVING COUNT(1) > 10\n",
    "        \"\"\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sufficient-maple",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "SELECT author, COUNT(1) AS NumPosts\n",
    "FROM `bigquery-public-data.hacker_news.comments`\n",
    "GROUP BY author\n",
    "HAVING COUNT(1) > 10000\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lonely-curve",
   "metadata": {},
   "source": [
    "### 2) Deleted comments\n",
    "\n",
    "How many comments have been deleted? (If a comment was deleted, the `deleted` column in the comments table will have the value `True`.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surprising-opinion",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "SELECT COUNT(1) \n",
    "FROM `bigquery-public-data.hacker_news.comments`\n",
    "WHERE deleted = True\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "amended-angola",
   "metadata": {},
   "source": [
    "**ORDER BY** is usually the LAST clause in your query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "talented-jewel",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "SELECT ID, Name, Animal\n",
    "FROM pets\n",
    "ORDER BY ID\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deluxe-stamp",
   "metadata": {},
   "outputs": [],
   "source": [
    "# it also works in columns with categorical values, it is going to sort it using an alpabethic approach\n",
    "\"\"\"\n",
    "SELECT ID, Name, Animal\n",
    "FROM pets\n",
    "ORDER BY Animal\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "together-climb",
   "metadata": {},
   "source": [
    "We can also use **DESC** to change the order if our sorting process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beautiful-sequence",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "SELECT ID, Name, Animal\n",
    "FROM pets\n",
    "ORDER BY Animal DESC\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "working-minority",
   "metadata": {},
   "source": [
    "**DATES**\n",
    "\n",
    "We have two ways that dates can be stored in a database, **DATE** and **DATETIME**\n",
    "\n",
    "he DATE format has the year first, then the month, and then the day. It looks like this:\n",
    "\n",
    "YYYY-[M]M-[D]D\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bulgarian-sweden",
   "metadata": {},
   "source": [
    "*EXTRACT* is the way to get a part of a date, like the year or the day. \n",
    "\n",
    "Meaning\t| extract field\n",
    "\n",
    "Year\t| YEAR\n",
    "\n",
    "Month\t|MONTH\n",
    "\n",
    "Day of month\t|DAY\n",
    "\n",
    "24 hour\t|HOUR\n",
    "\n",
    "Minute\t|MINUTE\n",
    "\n",
    "Seconds (including fractions)\t|SECOND\n",
    "\n",
    "Time zone hour\t|TIMEZONE_HOUR\n",
    "\n",
    "Time zone minute\t|TIMEZONE_MINUTE\n",
    "\n",
    "\n",
    "<img src=\"https://i.imgur.com/vhvHIh0.png\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "criminal-haven",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "SELECT Name, EXTRACT(DAY from Date) as Day\n",
    "FROM pets_with_date\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dietary-gilbert",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "SELECT Name, EXTRACT(WEEK from Date) as WEEK}\n",
    "FROM pets_with_date\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "initial-board",
   "metadata": {},
   "source": [
    "Example: *Which day of the week has the most fatal motor accidents?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "printable-rebate",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "SELECT EXTRACT(DAY FROM timestamp_of_crash) as day, COUNT(consecutive_number) as number_accidents\n",
    "FROM accidents\n",
    "GROUP BY day\n",
    "ORDER BY number_accidents DESC\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thrown-mississippi",
   "metadata": {},
   "source": [
    "Exercises\n",
    "\n",
    "The value in the `indicator_code` column describes what type of data is shown in a given row.  \n",
    "\n",
    "One interesting indicator code is `SE.XPD.TOTL.GD.ZS`, which corresponds to \"Government expenditure on education as % of GDP (%)\".\n",
    "\n",
    "### 1) Government expenditure on education\n",
    "\n",
    "Which countries spend the largest fraction of GDP on education?  \n",
    "\n",
    "To answer this question, consider only the rows in the dataset corresponding to indicator code `SE.XPD.TOTL.GD.ZS`, and write a query that returns the average value in the `value` column for each country in the dataset between the years 2010-2017 (including 2010 and 2017 in the average). \n",
    "\n",
    "Requirements:\n",
    "- Your results should have the country name rather than the country code. You will have one row for each country.\n",
    "- The aggregate function for average is **AVG()**.  Use the name `avg_ed_spending_pct` for the column created by this aggregation.\n",
    "- Order the results so the countries that spend the largest fraction of GDP on education show up first.\n",
    "\n",
    "In case it's useful to see a sample query, here's a query you saw in the tutorial (using a different dataset):\n",
    "```\n",
    "# Query to find out the number of accidents for each day of the week\n",
    "query = \"\"\"\n",
    "        SELECT COUNT(consecutive_number) AS num_accidents, \n",
    "               EXTRACT(DAYOFWEEK FROM timestamp_of_crash) AS day_of_week\n",
    "        FROM `bigquery-public-data.nhtsa_traffic_fatalities.accident_2015`\n",
    "        GROUP BY day_of_week\n",
    "        ORDER BY num_accidents DESC\n",
    "        \"\"\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dietary-flooring",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "SELECT contry_name, AVG(value) AS avg_ed_spending_pct, year\n",
    "FROM international_education\n",
    "WHERE indicator_name = \"SE.XPD.TOTL.GD.ZS\" AND year >= 2010 AND year <= 2017\n",
    "GROUP BY coutry_code\n",
    "ORDER BY avg_ed_spending_pct DESC\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "perfect-enhancement",
   "metadata": {},
   "source": [
    "### 2) Identify interesting codes to explore\n",
    "\n",
    "The last question started by telling you to focus on rows with the code `SE.XPD.TOTL.GD.ZS`. But how would you find more interesting indicator codes to explore?\n",
    "\n",
    "There are 1000s of codes in the dataset, so it would be time consuming to review them all. But many codes are available for only a few countries. When browsing the options for different codes, you might restrict yourself to codes that are reported by many countries.\n",
    "\n",
    "Write a query below that selects the indicator code and indicator name for all codes with at least 175 rows in the year 2016.\n",
    "\n",
    "Requirements:\n",
    "- You should have one row for each indicator code.\n",
    "- The columns in your results should be called `indicator_code`, `indicator_name`, and `num_rows`.\n",
    "- Only select codes with 175 or more rows in the raw database (exactly 175 rows would be included).\n",
    "- To get both the `indicator_code` and `indicator_name` in your resulting DataFrame, you need to include both in your **SELECT** statement (in addition to a **COUNT()** aggregation). This requires you to include both in your **GROUP BY** clause.\n",
    "- Order from results most frequent to least frequent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hungarian-payment",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "SELECT indicator_code, indicator_name, COUNT(1) AS num_rows\n",
    "FROM international_education\n",
    "WHERE year = 2016\n",
    "GROUP BY indicator_code, indicator_name\n",
    "HAVING COUNT(1) >= 175\n",
    "ORDER BY indicator_code DESC\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fifth-nudist",
   "metadata": {},
   "source": [
    "**WITH** in what's called a \"common table expresssion\" is a temporary table that you return within your query. CTEs are helpful for spliting your queries into readable chunks, and you can write queries against them.\n",
    "\n",
    "For example,\n",
    "\n",
    "you might want to use the pets table to ask questions about older animals in particular. So you can start by creating a CTE which only contains information about animals more than five years old like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "respiratory-jones",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "WITH Seniors AS\n",
    "(\n",
    "    SELECT ID, Name\n",
    "    FROM pets\n",
    "    WHERE Years_old > 5\n",
    "\n",
    ")\n",
    "SELECT ID\n",
    "FROM Seniors\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "enabling-championship",
   "metadata": {},
   "source": [
    "We're going to use a CTE to find out how many Bitcoin transactions were made each day for the entire timespan of a bitcoin transaction dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "theoretical-schedule",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "WITH time AS\n",
    "(\n",
    "    SELECT DATE(block_timestamp) AS trans_date\n",
    "    FROM transactions\n",
    ")\n",
    "SELECT trans_date, COUNT(1) as transactions\n",
    "FROM time\n",
    "GROUP BY trans_date\n",
    "ORDER BY trans_date\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "informal-western",
   "metadata": {},
   "source": [
    "### 3) Determine when this data is from\n",
    "\n",
    "If the data is sufficiently old, we might be careful before assuming the data is still relevant to traffic patterns today. Write a query that counts the number of trips in each year.  \n",
    "\n",
    "Your results should have two columns:\n",
    "- `year` - the year of the trips\n",
    "- `num_trips` - the number of trips in that year\n",
    "\n",
    "Hints:\n",
    "- When using **GROUP BY** and **ORDER BY**, you should refer to the columns by the alias `year` that you set at the top of the **SELECT** query.\n",
    "- The SQL code to **SELECT** the year from `trip_start_timestamp` is <code>SELECT EXTRACT(YEAR FROM trip_start_timestamp)</code>\n",
    "- The **FROM** field can be a little tricky until you are used to it.  The format is:\n",
    "    1. A backick (the symbol \\`).\n",
    "    2. The project name. In this case it is `bigquery-public-data`.\n",
    "    3. A period.\n",
    "    4. The dataset name. In this case, it is `chicago_taxi_trips`.\n",
    "    5. A period.\n",
    "    6. The table name. You used this as your answer in **1) Find the data**.\n",
    "    7. A backtick (the symbol \\`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "relative-company",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "WITH time AS\n",
    "(\n",
    "    SELECT EXTRACT(YEAR from trip_start_timestamp) as year\n",
    "    FROM chicago_taxi_trips\n",
    ")\n",
    "SELECT year, COUNT(1) AS num_trips\n",
    "FROM time\n",
    "GROUP BY year\n",
    "ORDER BY year\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "innovative-painting",
   "metadata": {},
   "source": [
    "### 4) Dive slightly deeper\n",
    "\n",
    "You'd like to take a closer look at rides from 2017.  Copy the query you used above in `rides_per_year_query` into the cell below for `rides_per_month_query`.  Then modify it in two ways:\n",
    "1. Use a **WHERE** clause to limit the query to data from 2017.\n",
    "2. Modify the query to extract the month rather than the year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cardiovascular-austin",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "WITH time AS\n",
    "(\n",
    "    SELECT EXTRACT(MONTH from trip_start_timestamp) AS month\n",
    "    FROM chicago_taxi_trips\n",
    ")\n",
    "SELECT month, COUNT(1)\n",
    "FROM time\n",
    "WHERE month = 2017\n",
    "GROUP BY month\n",
    "ORDER BY month\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "capital-prison",
   "metadata": {},
   "source": [
    "\n",
    "It's time to step up the sophistication of your queries.  Write a query that shows, for each hour of the day in the dataset, the corresponding number of trips and average speed.\n",
    "\n",
    "Your results should have three columns:\n",
    "- `hour_of_day` - sort by this column, which holds the result of extracting the hour from `trip_start_timestamp`.\n",
    "- `num_trips` - the count of the total number of trips in each hour of the day (e.g. how many trips were started between 6AM and 7AM, independent of which day it occurred on).\n",
    "- `avg_mph` - the average speed, measured in miles per hour, for trips that started in that hour of the day.  Average speed in miles per hour is calculated as `3600 * SUM(trip_miles) / SUM(trip_seconds)`. (The value 3600 is used to convert from seconds to hours.)\n",
    "\n",
    "Restrict your query to data meeting the following criteria:\n",
    "- a `trip_start_timestamp` between **2017-01-01** and **2017-07-01**\n",
    "- `trip_seconds` > 0 and `trip_miles` > 0\n",
    "\n",
    "You will use a common table expression (CTE) to select just the relevant rides.  Because this dataset is very big, this CTE should select only the columns you'll need to create the final output (though you won't actually create those in the CTE -- instead you'll create those in the later **SELECT** statement below the CTE).\n",
    "\n",
    "This is a much harder query than anything you've written so far.  Good luck!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stock-worry",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "WITH time as \n",
    "(\n",
    "    SELECT EXTRACT(HOUR from trip_start_timestamp) AS hour_of_day, trip_miles, trip_seconds\n",
    "    FROM taxi_trips\n",
    "    WHERE trip_start_timestamp > '2017-01-01' AND\n",
    "    trip_start_timestamp <  '2017-07-01' AND \n",
    "    tip_seconds > 0 AND\n",
    "    trip_miles > 0\n",
    ")\n",
    "SELECT hour_of_day, COUNT(1) AS num_trips, 3600 * SUM(trip_miles) / SUM(trip_seconds) AS avg_mph\n",
    "FROM time\n",
    "GROUP BY hour_of_day \n",
    "ORDER BY hour_of_day \n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "shaped-affairs",
   "metadata": {},
   "source": [
    "**JOIN** we can create a table with just two columns the name of the pet and the name of the owner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "graduate-official",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inner join\n",
    "\"\"\"\n",
    "SELECT p.Name AS Pet_Name, O.Name AS Owner_Name\n",
    "FROM pets AS p\n",
    "INNER JOIN owners AS o\n",
    "ON p.ID = o.PET_ID\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "infrared-challenge",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query to determine the number of files per license, sorted by number of files\n",
    "\"\"\"\n",
    "SELECT l.license, COUNT(1) as number_of_files\n",
    "FROM sample_files AS s \n",
    "INNER JOIN licenses AS l \n",
    "    ON s.repo_name = l.repo_name\n",
    "GROUP BY l.license\n",
    "ORDER BY number_of_files DESC\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "viral-courtesy",
   "metadata": {},
   "source": [
    "**WHERE** and the use of **LIKE** in text features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fossil-temperature",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "SELECT *\n",
    "FROM pets\n",
    "WHERE Name LIKE \"Ripley\"\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "marine-ferry",
   "metadata": {},
   "source": [
    "We can also use % as a \"wildcard\" for any number of characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "circular-classroom",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "SELECT *\n",
    "FROM pets\n",
    "WHERE Name LIKE \"%ipl%\"\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "appreciated-layer",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "WITH questions AS\n",
    "(\n",
    "    SELECT id\n",
    "    FROM posts_questions\n",
    "    WHERE tags LIKE '%bigquery%'\n",
    ")\n",
    "SELECT a.id, a.body, a.owner_user_id\n",
    "FROM post_answers AS a\n",
    "INNER JOIN questions AS q\n",
    "ON a.parent_id = q.id\n",
    "WHERE tags LIKE '%bigquery%'\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dress-edmonton",
   "metadata": {},
   "source": [
    "**JOINS**\n",
    "\n",
    "<img src=\"https://i.imgur.com/1Dvmg8S.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "orange-christian",
   "metadata": {},
   "source": [
    "<img src=\"https://i.imgur.com/oa6VDig.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "linear-auction",
   "metadata": {},
   "source": [
    "The query below pulls information from the stories and comments tables to create a table showing all stories posted on January 1, 2012, along with the corresponding number of comments. We use a LEFT JOIN so that the results include stories that didn't receive any comments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "balanced-fairy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query to select all stories posted on January 1, 2012, with number of comments\n",
    "\"\"\"\n",
    "WITH c AS\n",
    "(\n",
    "    SELECT parent, COUNT(*) AS num_comments\n",
    "    FROM comments\n",
    "    GROUP BY parent\n",
    ")\n",
    "SELECT\n",
    "FROM stores AS s\n",
    "LEFT JOIN c\n",
    "ON s.id = c.parent\n",
    "WHERE EXTRACT(DATE from s.time_ts) = '2012-01-01'\n",
    "ORDER BY c.num_comments DESC\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "blond-enhancement",
   "metadata": {},
   "source": [
    "Next, we write a query to select all usernames corresponding to users who wrote stories or comments on January 1, 2014. We use UNION DISTINCT (instead of UNION ALL) to ensure that each user appears in the table at most once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "norwegian-berlin",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "SELECT c.by\n",
    "FROM comments AS c\n",
    "WHERE EXTRACT(DATE from c.time_ts) = '2014-01-01'\n",
    "UNION DISTINCT\n",
    "SELECT s.by\n",
    "FROM stores AS s\n",
    "WHERE EXTRACT(DATE from s.time_ts) = '2014-01-01'\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "electronic-state",
   "metadata": {},
   "source": [
    "SELECT DISTINCT column1, column2, ...\n",
    "\n",
    "FROM table_name;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "touched-occupation",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    " SELECT q.id AS q_id,\n",
    "                  MIN(TIMESTAMP_DIFF(a.creation_date, q.creation_date, SECOND)) as time_to_answer\n",
    "              FROM `bigquery-public-data.stackoverflow.posts_questions` AS q\n",
    "                  INNER JOIN `bigquery-public-data.stackoverflow.posts_answers` AS a\n",
    "              ON q.id = a.parent_id\n",
    "              WHERE q.creation_date >= '2018-01-01' and q.creation_date < '2018-02-01'\n",
    "              GROUP BY q_id\n",
    "              ORDER BY time_to_answer\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "subjective-meditation",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "                  SELECT q.owner_user_id \n",
    "                  FROM `bigquery-public-data.stackoverflow.posts_questions` AS q\n",
    "                  WHERE EXTRACT(DATE FROM q.creation_date) = '2019-01-01'\n",
    "                  UNION DISTINCT\n",
    "                  SELECT a.owner_user_id\n",
    "                  FROM `bigquery-public-data.stackoverflow.posts_answers` AS a\n",
    "                  WHERE EXTRACT(DATE FROM a.creation_date) = '2019-01-01'\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hindu-basics",
   "metadata": {},
   "source": [
    "**Analytics functions** have an **OVER** clause, which defines the sets of rows used in each calculation. The **OVER** clause has three (optional) parts:\n",
    "\n",
    "+ The **PARTITION BY** clause divides the rows of the table into different groups. In the query above, we divide by id so that the calculations are separated by runner.\n",
    "+ The **ORDER BY** clause defines an ordering within each partition. In the sample query, ordering by the date column ensures that earlier training sessions appear first.\n",
    "+ The final clause (**ROWS BETWEEN 1 PRECEDING AND CURRENT ROW**) is known as a **window** frame clause. It identifies the set of rows used in each calculation. We can refer to this group of rows as a window. (Actually, analytic functions are sometimes referred to as analytic window functions or simply window functions!)\n",
    "\n",
    "<img src=\"https://i.imgur.com/GjiKlA7.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "transsexual-indian",
   "metadata": {},
   "source": [
    "*Window frame clauses*\n",
    "\n",
    "+ ROWS BETWEEN 1 PRECEDING AND CURRENT ROW - the previous row and the current row.\n",
    "+ ROWS BETWEEN 3 PRECEDING AND 1 FOLLOWING - the 3 previous rows, the current row, and the following row.\n",
    "+ ROWS BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING - all rows in the partition."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "asian-spyware",
   "metadata": {},
   "source": [
    "## Three types of analytic functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eligible-harmony",
   "metadata": {},
   "source": [
    "1. Analytic aggregate functions\n",
    "As you might recall, AVG() (from the example above) is an aggregate function. The OVER clause is what ensures that it's treated as an analytic (aggregate) function. Aggregate functions take all of the values within the window as input and return a single value.\n",
    "\n",
    "    + MIN() (or MAX()) - Returns the minimum (or maximum) of input values\n",
    "    + AVG() (or SUM()) - Returns the average (or sum) of input values\n",
    "    + COUNT() - Returns the number of rows in the input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "settled-melissa",
   "metadata": {},
   "source": [
    "2.  Analytic navigation functions\n",
    "Navigation functions assign a value based on the value in a (usually) different row than the current row.\n",
    "\n",
    "    + FIRST_VALUE() (or LAST_VALUE()) - Returns the first (or last) value in the input\n",
    "    + LEAD() (and LAG()) - Returns the value on a subsequent (or preceding) row"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "improved-grass",
   "metadata": {},
   "source": [
    "3. Analytic numbering functions\n",
    "Numbering functions assign integer values to each row based on the ordering.\n",
    "\n",
    "    + ROW_NUMBER() - Returns the order in which rows appear in the input (starting with 1)\n",
    "    + RANK() - All rows with the same value in the ordering column receive the same rank value, where the next row receives a rank value which increments by the number of rows with the previous rank value."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rising-thunder",
   "metadata": {},
   "source": [
    "**Common Table Expressions (CTEs)**\n",
    "\n",
    "+ Auxiliary statements for use in large query\n",
    "+ Create temporary tables used only within a query\n",
    "+ Used to simplify complex queries that would otherwise require subqueries\n",
    "+ Recursive CTEs enable queries over hirarchical data\n",
    "\n",
    "The CTEs are defined using WITH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "professional-antarctica",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Each row of the table corresponds to a different bike trip, and we can use an analytic function to \n",
    "# calculate the cumulative number of trips for each date in 2015.\n",
    "\n",
    "\"\"\"\n",
    "WITH trips_by_day AS \n",
    "(\n",
    "    SELECT DATE(start_date) AS trip_date,\n",
    "    COUNT(*) AS num_trips\n",
    "    FROM `bigquery-public-data.san_francisco.bikeshare_trips`\n",
    "    WHERE EXTRACT(YEAR from trip_date) = 2015\n",
    "    GROUP BY trip_date\n",
    ")\n",
    "SELECT *,\n",
    "    SUM(num_trips)\n",
    "        OVER(\n",
    "        ORDER BY trip_date\n",
    "        ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW        \n",
    "        ) AS cumulative_trips\n",
    "    FROM trips_by_day\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "naughty-hands",
   "metadata": {},
   "source": [
    "The next query tracks the stations where each bike began (in start_station_id) and ended (in end_station_id) the day on October 25, 2015.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tracked-procurement",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "SELECT bike_number\n",
    "    TIME(start_date) AS trip_date,\n",
    "    FIRST_VALUE(start_station_id)\n",
    "    OVER (\n",
    "        PARTITION BY bike_number\n",
    "        ORDER BY start_date\n",
    "        ROWS BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING\n",
    "    ) AS first_station_id\n",
    "    LAST_VALUE(end_statikon_id)\n",
    "    OVER (\n",
    "        PARTITION BY bike_number\n",
    "        ORDER BY start_date\n",
    "        ROWS BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING\n",
    "    ) AS last_station_id\n",
    "    start_station_id,\n",
    "    end_station_id\n",
    "    FROM bigquery-public-data.san_francisco.bikeshare_trips`\n",
    "    WHERE DATE(start_date) = '2015-10-25'\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "detailed-fields",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "described-webmaster",
   "metadata": {},
   "source": [
    "statistical queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "northern-syracuse",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "select \n",
    "\tdepartment_id, sum(salary), \n",
    "\tround(avg(salary),2), \n",
    "\tround(var_pop(salary),2), \n",
    "\tround(stddev_pop(salary),2)\n",
    "from\n",
    "\tdata_sci.employees\n",
    "group by department_id \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "guided-fields",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "select \n",
    "\tupper(department_name)\n",
    "from data_sci.company_departments\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "awful-namibia",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the initial upper case\n",
    "\"\"\"\n",
    "select \tinitcap(department_name)from data_sci.company_departments\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "collect-jewelry",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove spaces\n",
    "\n",
    "\"\"\"\n",
    "select \n",
    "\tltrim(' Kelly') = 'Kelly'\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sized-figure",
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate two strings ||\n",
    "\"\"\"\n",
    "select \n",
    "\tjob_title || '-' || last_name\n",
    "from \n",
    "\tdata_sci.employees\n",
    "\"\"\"\n",
    "\n",
    "# PAY ATTENTION TO THE NULL VALUES USING ||\n",
    "\n",
    "\"\"\"\n",
    "select \n",
    "\tCONCAT(job_title, '-', last_name)\n",
    "from \n",
    "\tdata_sci.employees\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "typical-reward",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract substrings from strings\n",
    "\"\"\"\n",
    "select \n",
    "\tsubstring('abcdefghi', 1, 3) test_string\n",
    "\t\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "select \n",
    "\tsubstring('abcdefghi' from 1 for 3) test_string\n",
    "\t\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "select\n",
    "\tjob_title, (job_title like '%assistant%') is_assistant\n",
    "from\n",
    "\tdata_sci.employees\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spiritual-protein",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter with regular expressions\n",
    "\"\"\"\n",
    "select distinct\n",
    "\tjob_title\n",
    "from \n",
    "\tdata_sci.employees\n",
    "where\n",
    "\tjob_title  like 'vp%'\n",
    "or\n",
    "\tjob_title  like 'web%'\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "select distinct\n",
    "\tjob_title\n",
    "from \n",
    "\tdata_sci.employees\n",
    "where\n",
    "\tjob_title similar to '(vp%|web%)'\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "automatic-introduction",
   "metadata": {},
   "source": [
    "+ Soundex returns a code representing the sound of a string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "future-peace",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "select difference('Postgres', 'Kostgres')\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "select levenshtein('Postgres', 'Kostgres')\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "criminal-republican",
   "metadata": {},
   "source": [
    "Use ROLLUP to create subtotals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "careful-stranger",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "select \n",
    "\tcr.country_name, cr.region_name, count(e.*)\n",
    "from \n",
    "\tdata_sci.employees e\n",
    "join\n",
    "\tdata_sci.company_regions cr\n",
    "on\n",
    "\te.region_id = cr.id\n",
    "group by \n",
    "\trollup(cr.country_name, cr.region_name)\n",
    "order by\n",
    "\tcr.country_name, cr.region_name\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "binding-killer",
   "metadata": {},
   "source": [
    "CUBE to total across dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "occupational-russian",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "select \n",
    "\tcr.country_name, \n",
    "\tcr.region_name, \n",
    "\tcd.department_name,\n",
    "\tcount(e.*)\n",
    "from \n",
    "\tdata_sci.employees e\n",
    "join\n",
    "\tdata_sci.company_regions cr\n",
    "on\n",
    "\te.region_id = cr.id\n",
    "join \n",
    "\tdata_sci.company_departments cd\n",
    "on\n",
    "\te.department_id = cd.id\n",
    "group by \n",
    "\tcube(cr.country_name, \n",
    "\t\t cr.region_name,\n",
    "\t\tcd.department_name)\n",
    "order by\n",
    "\tcr.country_name, \n",
    "\t\t cr.region_name,\n",
    "\t\tcd.department_name\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sought-delicious",
   "metadata": {},
   "source": [
    "gets the top-N queries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fourth-albert",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "select\n",
    "\t* \n",
    "from \n",
    "\tdata_sci.employees\n",
    "order by\n",
    "\tsalary desc\n",
    "fetch first 10 rows only\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gothic-adapter",
   "metadata": {},
   "source": [
    "example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "banner-tiffany",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "select\n",
    "\tdepartment_id, SUM(salary)\n",
    "from \n",
    "\tdata_sci.employees\n",
    "group by department_id\n",
    "HAVING\n",
    "\tsum(salary) > 5000000\t\n",
    "ORDER BY\n",
    "\tsum(salary) desc\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unable-modeling",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "select \n",
    "\tdepartment_id,\n",
    "\tlast_name,\n",
    "\tsalary,\n",
    "\tfirst_value(salary) over (partition by department_id order by salary asc)\n",
    "from\n",
    "\tdata_sci.employees\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fresh-denial",
   "metadata": {},
   "source": [
    "+ Nth_tile creates subgroups base on an ordering. By using nth_value with a parameter of 10, you can create deciles."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "progressive-career",
   "metadata": {},
   "source": [
    "quartiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rubber-conditions",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "select \n",
    "\tdepartment_id,\n",
    "\tsalary,\n",
    "\tntile(4) over (partition by department_id order by salary desc) as quartile\n",
    "from\n",
    "\tdata_sci.employees\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "protecting-dominican",
   "metadata": {},
   "source": [
    "+ rank function groups the data\n",
    "+ led // Lead is used to return values from a row later in a result set.\n",
    "+ lag // Lag is used to return values for a row earlier in a result set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "desirable-american",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "select \n",
    "\tdepartment_id,\n",
    "\tlast_name,\n",
    "\trank() over (partition by department_id order by salary desc)\n",
    "from\n",
    "\tdata_sci.employees\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "select \n",
    "\tdepartment_id,\n",
    "\tlast_name,\n",
    "\trank() over (order by salary desc)\n",
    "from\n",
    "\tdata_sci.employees\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gothic-identity",
   "metadata": {},
   "source": [
    "+ width_bucket / Width_buckets is used to assign a row to a bucket based on a value.\n",
    "+ cume_dist / cummulative distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mounted-frontier",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "select \n",
    "\tdepartment_id,\n",
    "\tlast_name,\n",
    "\tsalary,\n",
    "\twidth_bucket(salary, 0,  150000, 10)\n",
    "from\n",
    "\tdata_sci.employees\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "select \n",
    "\tdepartment_id,\n",
    "\tlast_name,\n",
    "\tsalary,\n",
    "\tcume_dist () over (order by salary desc)\n",
    "from\n",
    "\tdata_sci.employees\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "select \n",
    "\tdepartment_id,\n",
    "\tlast_name,\n",
    "\tsalary,\n",
    "\tround((cume_dist () over (order by salary desc) *100)::numeric,2)\n",
    "from\n",
    "\tdata_sci.employees\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "talented-treasure",
   "metadata": {},
   "source": [
    "# advanced SQL for data science"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abandoned-planet",
   "metadata": {},
   "source": [
    "**Denormalization**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "extraordinary-cocktail",
   "metadata": {},
   "source": [
    "*Partitioning*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reserved-voltage",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "CREATE TABLE iot.sensor_msmt (\n",
    "    sensor_id int not null,\n",
    "    msmt_date date not null,\n",
    "    temperature int,\n",
    "    humidity int)\n",
    "    PARTITION BY RANGE (msmt_date);\n",
    "    \n",
    "CREATE TABLE io_sensor_msmt_y2021m01 PARTITION OF iot.sensor_msmt\n",
    "    FOR VALUES FROM ('2021-01-01') TO ('2021-01-31');\n",
    "\n",
    "CREATE TABLE io_sensor_msmt_y2021m01 PARTITION OF iot.sensor_msmt\n",
    "    FOR VALUES FROM ('2021-02-01') TO ('2021-02-28');\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "precious-signature",
   "metadata": {},
   "source": [
    "*Materialized*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "professional-norwegian",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "CREATE MATERIALIZED VIEW landon.mv_locations_expenses AS\n",
    "(SELECT \n",
    "    l.hotel_id, l.city, l.state_province, l.country,\n",
    "    e.year, e.annual_payroll, e.health_insurance, e.supplies\n",
    "FROM\n",
    " landon.expenses e\n",
    "LEFT JOIN\n",
    "    landon.expenses e\n",
    "ON (l.hotel_id = e.hotel_id)\n",
    ")\n",
    "\n",
    "SELECT * FROM landon.mv_location_expenses;\n",
    "\n",
    "REFRESH MATERIALIZED VIEW landon.mv_locations_expenses;\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "linear-efficiency",
   "metadata": {},
   "source": [
    "## B-Tree Indexes\n",
    "\n",
    "It reduces need to scan data blocks, comes t at cost of additional writes during data loading, \n",
    "+ the higer the cardinality of indexed data, the better the performance improvement\n",
    "+ nhot used in analyutical dtabases\n",
    "\n",
    "*types:*\n",
    "+ B-tree\n",
    "+ Bitmap\n",
    "+ Hash\n",
    "+ Special-purpose indexes\n",
    "\n",
    "\n",
    "B: balanced, the B-tree indexes has a logarithmic time narrows down the search by repeatedly having the dataset until you find the target value\n",
    "\n",
    "Bitmap, the idea is to map the values using a bit string. This is a good way to deal with read-intensive use cases, few writes.\n",
    "\n",
    "\n",
    "Hash indexes use hash functions for mapping arbitrary length data to a fixed-size string\n",
    "\n",
    "GiST (Generalized Search Tree) and SP-GiST indexes are specialized index provied by PostGres, GiST is a balance tree-structure access method. SP-GiST ((Space-partitioned GiST) is useful for non-balanced data structures\n",
    "\n",
    "GIN (Generalized Inverted index), it is used when data to be indexed are composite values.\n",
    " + Insertion can slow because many keys may be inserted for each item, for example, many words in a document. \n",
    " + index stores data in pairs(key, posting list)\n",
    " + insertion can slow \n",
    " \n",
    "BRIN - Block range Index\n",
    " + It is used with very large tables\n",
    " + column data has a correlation with physical location, such as postal code and dates.\n",
    " + it stores summary information about block ranges\n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "north-richmond",
   "metadata": {},
   "source": [
    "## From SQL to execution plans\n",
    "\n",
    "+ Cost based on Number of Rows\n",
    " - Scanning small tables is efficient\n",
    "+ Indexes save scanning\n",
    " - indexes are ordered\n",
    " - faster to seach index for an attribute value\n",
    " - points to a particualr row\n",
    " \n",
    "+ *Nested loop join*: compare all rows in both tables to each other\n",
    "+ *Hash join*: calculate hash value of key; join based on matching hash values\n",
    "+ *Sort merge*: sort both tables and then join rows while taking advantage of order\n",
    "\n",
    "**Analyze**\n",
    "\n",
    "+ Plan builder relies on statistics about data in tables\n",
    "+ Usually statistics are kept up to date \n",
    "+ Sometimes statistics cat get out of date\n",
    "+ ANALYZE command updates statistics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "second-store",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate time seriedata\n",
    "\"\"\"\n",
    "insert into iot.sensor_msmt\n",
    "    (with sensors_datetimes as\n",
    "    (select \n",
    "        * \n",
    "    from\n",
    "    (select * from generate_series(1,100)) as t1,\n",
    "    (select * from generate_series('2021-01-01 00:00'::timestamp,\n",
    "                                   '2021-02-15 00:00'::timestamp,\n",
    "                                   '1 minute')) as t2\n",
    "   )\n",
    "   select \n",
    "       sd.*,\n",
    "       floor(random()*30) as temperature\n",
    "       floor(random()*20) as humidity,\n",
    "    from \n",
    "        sensors_datetimes sd\n",
    "    )\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "necessary-brunswick",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "explain select\n",
    "    s.sensor_name,\n",
    "    sms.msmt_date,\n",
    "    sm.temperature,\n",
    "    sm.humidity\n",
    "from\n",
    "    iot.sensor_msmt as sm\n",
    "left join\n",
    "    iot.sensors as s\n",
    "on\n",
    "    sm.sensor_id = s.id\n",
    "where\n",
    "    s.id = 30\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "experienced-fourth",
   "metadata": {},
   "source": [
    "+ Use EXPLAIN to view the query execution plan\n",
    "+ Look for full scans and indexing opportunities\n",
    "+ Assess how indexes are used with joins\n",
    "+ Look for oportunities to filter the dataset size\n",
    "+ Run ANALYZE to ensure statistics are up to date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "scheduled-bottom",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "explain select \n",
    "    * \n",
    "from \n",
    "    iot.sensor_smsmt\n",
    "where\n",
    "    sensor_id between 10 and 20\n",
    "    \n",
    "create index idx_sensor_msmt_id on iot.sensor_msmt(sensor_id)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "special-cosmetic",
   "metadata": {},
   "source": [
    "+ Aggregate\n",
    "+ String manipulation\n",
    "+ Pattern matching\n",
    "+ Date and time\n",
    "+ Geometric\n",
    "---\n",
    "A SQL function can return of last statements:\n",
    "+ last statement must be a SELECT\n",
    "+ or the function must be declared VOID\n",
    "+ it can contain:\n",
    "    - SELECT, INSERT, UPDATE, DELETE\n",
    "    \n",
    "CREATE FUNCTION\n",
    "+ creates new function\n",
    "\n",
    "CREATE OR REPLACE FUNCTION\n",
    "+ updates the definition of function if it exists\n",
    "+ creates a new function if it does not exist\n",
    "\n",
    "DROP FUNCTION and CREATE FUNCTION\n",
    "+ Need to drop existing rules, views, triggers, and so on, that refer to the dropped function\n",
    "\n",
    "---\n",
    "\n",
    "*Harmonic mean*\n",
    "\n",
    "$\\frac{2xy}{x+y}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "proof-breath",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nCREATE FUNCTION harmonic_mean(x numeric, y numeric)\\nRETURNS numeric\\nAS $$\\n    SELECT\\n    round(((2 * x * y)/ (x+y))::numeric ,2)\\n    $$ LANGUAGE SQL;\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "CREATE FUNCTION harmonic_mean(x numeric, y numeric)\n",
    "RETURNS numeric\n",
    "AS $$\n",
    "    SELECT\n",
    "    round(((2 * x * y)/ (x+y))::numeric ,2)\n",
    "    $$ LANGUAGE SQL;\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sudden-convenience",
   "metadata": {},
   "source": [
    "*Function overloading* \n",
    "\n",
    "+ A single function can have multiple definitions\n",
    "+ Different definitions require different parameter signatures\n",
    "+ Useful when the same function can apply to different data types\n",
    "+ Avoids ambiguities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unusual-warren",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "CREATE FUNCTION harmonic_mean(x text, y text)\n",
    "RETURNS numeric\n",
    "AS $$\n",
    "    SELECT\n",
    "    round(((2 * x::numeric * y::numeric)/ (x::numeric+y::numeric))::numeric ,2)\n",
    "    $$ LANGUAGE SQL;\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "recovered-roller",
   "metadata": {},
   "source": [
    "*Function volatility*\n",
    "\n",
    "It can be used to improve the performance of our functions, because the function have a volality classification\n",
    "+ volatile, default classification. The function is reevaluated at every row the function is needed\n",
    "+ stable, cannot modify the database. Guaranteed to return the same results given the same arguments for all rows within a single statement\n",
    "+ immutable, if function has no side effects but uses another funciton that can change value in a query, the user defined must be VOLATILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "premium-blade",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "CREATE FUNCTION harmonic_mean(x numeric, y numeric)\n",
    "RETURNS numeric\n",
    "AS $$\n",
    "    SELECT\n",
    "    round(((2 * x * y)/ (x+y))::numeric ,2)\n",
    "    $$ LANGUAGE SQL IMMUTABLE;\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "processed-brunswick",
   "metadata": {},
   "source": [
    "*PL/Python functions*\n",
    "\n",
    "it can write PostgreSQL functions in Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stainless-sharing",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "CREATE FUNCTION pymax (x integer, y integer)\n",
    "    RETURNS integer\n",
    "AS $$\n",
    "    if x > y:\n",
    "        return x\n",
    "    $$ LANGUAGE plpython3u;\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "competitive-marketplace",
   "metadata": {},
   "outputs": [],
   "source": [
    "# palindrome\n",
    "\"\"\"\n",
    "CREATE OR REPLACE FUNCTION is_palindrome (str text) RETURNS boolean\n",
    "AS $$\n",
    "    SELECT reverse(str) = str    \n",
    "$$ LANGUAGE SQL IMMUTABLE;\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "published-livestock",
   "metadata": {},
   "source": [
    "*Federated queries*\n",
    "\n",
    "FDW and datalinks\n",
    "+ Foreign-data wrappers\n",
    "+ Allow for viewing data outside of the database\n",
    "+ datalinks provide database functionality\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "subjective-bonus",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "CREATE EXTENSION postgres_dfw\n",
    "CREATE SERVER external_dv_server\n",
    "    FOREIGN DATA WRAPPER postgres_fdw\n",
    "    OPTIONS (host 'mydb.example.com', dbname 'data_warehouse')\n",
    "    \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "polyphonic-decision",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map users\n",
    "\"\"\"\n",
    "CREATE USER MAPPING FOR CURRENT_USER\n",
    "    SERVER external_db_server\n",
    "    OPTIONS (user 'analyst', pasd 'asdaavasdsad!');\n",
    "\"\"\"\n",
    "\n",
    "# Create foreign table\n",
    "\"\"\"\n",
    "CREATE FOREIGN TABLE page_visit_log (\n",
    "    log_time timestamp,\n",
    "    user_name text,\n",
    "    web_page text\n",
    ") SERVER log_data\n",
    "OPTIONS (filename '/app/ecommerce/logs/page_vists.log', format 'csv');\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reduced-sullivan",
   "metadata": {},
   "source": [
    "*Bloom filters*\n",
    "\n",
    "+ Space efficient method for determining set membership\n",
    "+ Useful for quickly finding sets with values \n",
    "+ it is a lossy representation of data\n",
    "+ probabilistic data structure\n",
    " - may produce false positives \n",
    " - never produces false negatives\n",
    " - accuracy is a function of the number of bits used in the filter\n",
    "+ it is useful when the table has many attributes\n",
    "\n",
    "the limitations\n",
    "+ support only the quality on int4 and text data types\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pressing-offense",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "CREATE EXTENSION bloom\n",
    "CREATE INDEX idx-locations_blm ON locations\n",
    "    USING bloom (city, state_providence, country)\n",
    "    WITH (length=128);\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "juvenile-chess",
   "metadata": {},
   "source": [
    "*hstore*\n",
    "\n",
    "data type for storing sets of key-value pairs, columns defined as hstore data type\n",
    "\n",
    "+ It is useful when large number of attributes are not used\n",
    "+ GIN and GiST indexes can index all keys\n",
    "+ Example use case: catalog\n",
    "\n",
    "Some limitations are:\n",
    "+ all keys and values are stored as strings\n",
    "+ do not support hierarchical data structures\n",
    "+ Json and xml can be better options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hollywood-naples",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "CREATE EXTENSION hstore\n",
    "CREATE TABLE books(\n",
    "id serial primary key,\n",
    "title text,\n",
    "attributes hstore\n",
    ");\n",
    "\"\"\"\n",
    "#Key-value represented as string\n",
    "\"\"\"\n",
    "key1 => value1, key2=> value2,..\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "piano-administration",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "INSERT INTO books (title, attributes) VALUES\n",
    "('SQL for Data Science', \n",
    "'language=>English, page_cnt=>500, pub_year=>2021');\n",
    "\n",
    "INSERT INTO books (title, attributes) VALUES\n",
    "('SQL for Data Science 2', \n",
    "'language=>English, page_cnt=>600, pub_year=>2021');\n",
    "\n",
    "SELECT title, attributes->'page_cnt' pc FROM books\n",
    "WHERE attributes-> 'page_cnt' = '500';\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pleased-baseline",
   "metadata": {},
   "source": [
    "*JSONB supports nested JSON structures*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "demonstrated-static",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "CREATE TABLE customer_summary(\n",
    "    id serial primary_key,\n",
    "    customer_doc jsonb   \n",
    ");\n",
    "INSERT INTO customer_summary (customer_doc) VALUES\n",
    "('{\"customer_name\": {\"fist_name\": \"Alice\",\n",
    "\"last_name\": \"Jonhson\"}}')\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "SELECT\n",
    " customer_doc -> 'customer_name'\n",
    "FROM \n",
    " customer_summary\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "SELECT\n",
    " customer_doc -> 'customer_name' ->> 'first_name'\n",
    "FROM \n",
    " customer_summary\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sufficient-detective",
   "metadata": {},
   "source": [
    "*Hierarchical data and Itrees*\n",
    "\n",
    "+ Recursive common table expression (CTE)\n",
    "+ materialized paths, each mnode in tree is in its own row\n",
    "    - path colmun contains string of ancestors\n",
    "    - search and pattern match string\n",
    "    \n",
    " *Itree* is a PostgreSQL extension for working with trees and paths\n",
    " + @> - ancestor\n",
    " + <@ - descendent\n",
    " + || - concatenate tree paths\n",
    " + ~ - does Itree match and Itree text query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "straight-promotion",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "CREATE TABLE paths_to_nodes(\n",
    "    id serial primary key,\n",
    "    node text,\n",
    "    path ltree\n",
    ");\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "CREATE EXTENSION ltree;\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "CREATE INDEX idx_paths_to_nodes ON paths_to_nodes USING gist(path)\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "SELECT * FROM paths_to_nodes\n",
    "WHERE 'A.B' @> path\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "SELECT * FROM paths_to_nodes\n",
    "WHERE '*.B.*{0,2}' - path\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "SELECT * FROM paths_to_nodes\n",
    "WHERE '*.B.*{0,2}' - path\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "synthetic-oakland",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
