{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "691fd552-4a9d-4d5c-b135-d9fff2a65696",
   "metadata": {},
   "source": [
    "![DLI Logo](../assets/DLI_Header.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efcaa377",
   "metadata": {},
   "source": [
    "# Training Data Extraction\n",
    "\n",
    "In this lab we are going to walk through an implementation of parts of [\"Extracting Training Data from Large Language Models\"](https://arxiv.org/pdf/2012.07805.pdf) by Carlini et al.  In what might be a familiar refrain by now, please temper your expectations. We use smaller LLMs to allow inference to be fast enough for the lab, and smaller models have less capacity to exactly memorize data.\n",
    "\n",
    "If you're following along in the paper, the bits you're probably most likely to be interested in start around page 5 (section 4).\n",
    "\n",
    "The main idea of the attack is that the model should be 'more confident' in producing text that it has memorized exactly; to exploit this, we first ask the model to generate a large quantity of text, and then use the model to check its own work and filter down to candidate productions that are likely to have been memorized exactly.\n",
    "\n",
    "To improve this attack, the authors try two additional generation strategies:\n",
    "1. Start with a high temperature during generation, and rapidly drop it to a normal level.  This encourages diversity in the first few tokens of model output before attempting to make it produce sequences that the model assigns very high probability to (which by assumption are more likely to have been memorized).\n",
    "2. \"Prime\" the model with a number of source texts from the Internet, likely to be the same as or similar to the model training data (we leave this as an exercise)\n",
    "\n",
    "They also introduce several modified scoring rules, in addition to just the model's probability estimate (which is a direct map to \"perplexity\" which they refer to in the paper):\n",
    "1. Compare to another neural language model (left as an exercise)\n",
    "2. Compare to zlib compression \n",
    "3. Compare to lowercased text\n",
    "4. Perplexity on a sliding window of text, rather than the entire text at once (not implemented)\n",
    "\n",
    "\n",
    "Having generated significant amounts of text, as well as several different ways to score it, they take the highest scores from each combination of generation method and scoring, and evaluate it by hand to determine the rate of accurate training data recovery.\n",
    "\n",
    "The final test, of course, is comparing it to the actual training data to determine whether or not it's a \"hit\", however we don't have access to that, so we're going to have to settle for things that look plausible, and Google searches.\n",
    "\n",
    "By the time you've finished this lab, you'll have a good idea of how each of these metric perform, and how to use them to assess the likelihood that a given sample was included in training data.  You'll also have had a bit of practice reading an academic paper and extracting the relevant bits of information from it to implement a new (to you) attack.\n",
    "\n",
    ":::{admonition} Exercise\n",
    "Go read the Wikipedia page on[ perplexity](https://en.wikipedia.org/wiki/Perplexity#Perplexity_of_a_probability_model).  If you need to, review some [material on negative log-likelihood](https://towardsdatascience.com/cross-entropy-negative-log-likelihood-and-all-that-jazz-47a95bd2e81).  How are the two related?  If we order by negative log likelihood loss, is the order the same or different as if we order by perplexity?\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d1376e6",
   "metadata": {},
   "source": [
    ":::{admonition} Exercise\n",
    "\n",
    "Now that we've laid out the big ideas of the paper, take fifteen minutes, read it for yourself, and try to convince yourself you understand how they did the evaluation.  See if you can pick out the details in how they generated the samples: what top-k? what temperature? how many new tokens per sample?\n",
    "\n",
    "Most attacks in this space appear in papers like this first; the better you get at skimming them and picking out the key bits, the better you'll be at keeping up with the fire hose.  Eat your vegetables.\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbae6515",
   "metadata": {},
   "source": [
    ":::{warning}\n",
    "\n",
    "We're doing a lot of mucking about with tensors that go to and from the GPU, as well as asking you to experiment with indexing into and slicing on-GPU arrays; the potential for CUDA errors throwing up the `RuntimeError: CUDA error: device-side assert triggered` message is very high.  If you get a CUDA error, this usually disables GPU access from the python process until the kernel is reset.\n",
    "\n",
    "If you encounter CUDA errors while running this lab, you need to do the following:\n",
    "1. Go to the 'Running terminals and kernels' tab on the left (below the folder icon) and terminate all other terminals.\n",
    "2. Restart the kernel for the current notebook from the 'Kernel' menu\n",
    "3. Fix the offending code\n",
    "4. Re-run the notebook from the beginning\n",
    "\n",
    "If you still run into an error, please let us know.\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64207613",
   "metadata": {},
   "source": [
    "## Model Loading Boilerplate\n",
    "\n",
    "Nothing much new here -- though do note the use of a 'large' model as well as the way we prompt with a special token below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92a49229",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT CHANGE\n",
    "\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='0'\n",
    "\n",
    "# for scoring outputs\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import zlib, sys\n",
    "\n",
    "# LLM imports\n",
    "import transformers\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "import torch\n",
    "torch.cuda.set_device(0)\n",
    "device = \"cuda:0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b37a045c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT CHANGE\n",
    "\n",
    "from transformers.utils import logging\n",
    "\n",
    "# This suppresses a recurring warning message that pops up because we're going to spend a lot of time trying to generate sequences that start with a special token\n",
    "logging.set_verbosity_error()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac4e522b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# DO NOT CHANGE\n",
    "\n",
    "# We're going to try gpt-large here to have a slightly better chance of retrieving memorized data\n",
    "# model_id = \"gpt2-large\"\n",
    "model_id = \"gpt2-xl\"\n",
    "device = 'cuda:0'\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id).to(device)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f5257ce",
   "metadata": {},
   "source": [
    "With the boilerplate out the the way, we're going to call the model once to see if it works -- note that the model needs a first token to start with, so we're going to use the 'bos' (beginning of sequence) token.  This is the same token (\"<|endoftext|>\") as the padding and end of text tokens.\n",
    "\n",
    "Side note worth remembering: most tokenizers will find the longest match when tokenizing; even though \"end\" \"of\" and \"text\" are all individual tokens, the fact that \"<|endoftext|>\" is registered as its own token means that the tokenizer will replace it with that single token rather than all three.\n",
    "\n",
    "Another side note: what happens if you insert the \"<|endoftext|>\" token into a prompt for GPT2?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "feca9108",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|endoftext|>As the new year dawns this week, we would be foolish to forget about the many, major, and horrifying problems that still haunt our country. The problem is that there are some things that the mass media will never show.\n",
      "\n",
      "Case in point: a massive, well-organized effort to shut down conservative thought by infiltrating and subverting the very institutions of higher learning.\n",
      "\n",
      "How did this all begin?\n",
      "\n",
      "It all started in September, when a group of leftists went to Columbia University and tried to bully Professors Nicholas and Erika Christakis into deleting a critical opinion piece the couple had posted to Facebook to give their students some insight into what it means for them to be a faculty member.\n",
      "\n",
      "In an interview with MSNBC's Chris Hayes, Erika (the author of the article) was quick to point out that Columbia wasn't the first school to invite them to speak at.\n",
      "\n",
      "\"I think there are a lot of examples in universities across the country,\" she explained, pointing to the efforts that were made to shut down Christina Hoff Sommers' speech at Brandeis this summer.\n",
      "\n",
      "What was not previously known is that the Christakises were at the center of a similar situation last year at Yale when students and students\n"
     ]
    }
   ],
   "source": [
    "# DO NOT CHANGE\n",
    "\n",
    "text = tokenizer.special_tokens_map['bos_token']\n",
    "\n",
    "inputs = tokenizer(text, return_tensors=\"pt\").to(device)\n",
    "outputs = model.generate(**inputs, do_sample=True, \n",
    "                         max_new_tokens=256, \n",
    "                         top_k=40,\n",
    "                         return_dict_in_generate=True,\n",
    "                         output_scores = True,\n",
    "                         pad_token_id=50256,\n",
    "                        )\n",
    "\n",
    "print(tokenizer.decode(outputs.sequences[0], skip_special_tokens=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e135ba6",
   "metadata": {},
   "source": [
    "## Scoring\n",
    "\n",
    "Here we define our scoring function -- we show the model the sentence we produced, and ask it how likely it would have been to predict the n-th letter given n-1 letters. This is exactly the quantity the model computes during training, so we can use the model loss that's built in. Look at the equation at the end of section 4.2; the quantity inside the parentheses is the same as the model loss, they then exponentiate it to find perplexity. The exponentiation operation changes the magnitude of the score, but not the order in which we'd sort the samples (a higher NLL would always have a higher perplexity than a lower NLL sample), so we're going to ignore that step for now. The same logic as with 'loss' applies: the lower it is, the more likely the model thinks the token is -- if it's perfectly memorized a sample, it should have very low loss for that exact sample.\n",
    "\n",
    "Worth noting the care we're taking to `.detach()` and explicitly mark items for deletion/collection -- when working at a low level with tensors that are on the GPU, creating VRAM \"memory leaks\" is very easy and annoying."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e89cf420",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT CHANGE\n",
    "\n",
    "def score_outputs(outputs, model = model):\n",
    "    input_ids = outputs.clone()\n",
    "    target_ids = input_ids.clone()\n",
    "    # detach() to explicitly break gradients and avoid CUDA memory 'leaks'\n",
    "    loss = model(input_ids, labels = target_ids).loss.detach().item()\n",
    "    del input_ids, target_ids #extra paranoia for CUDA memory\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a598babe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.9576294422149658"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DO NOT CHANGE\n",
    "\n",
    "score_outputs(outputs.sequences[0], model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68ae05fa",
   "metadata": {},
   "source": [
    ":::{admonition} Exercise!\n",
    "Inspect the full results from calling the model: `model(input_ids, labels=target_ids)`   What do they represent? \n",
    "\n",
    "Look up the softmax function if you don't remember it.  What do we have to do to the logits to compute the loss function from them?\n",
    "\n",
    "BONUS challenge: Read up on the [log-sum-exp](https://gregorygundersen.com/blog/2020/02/09/log-sum-exp/) trick and see if you can compute the loss from logits and get the same result as the function above.\n",
    "\n",
    "If you get stuck, check out the [answer key](answers-4_LLM.ipynb) notebook.\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eb511e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here \n",
    "import torch.nn.functional as F\n",
    "\n",
    "def compute_loss_from_logits(logits, targets):\n",
    "    shift_logits=logits[:-1].contiguous()\n",
    "    shift_targets=targets[1:].contiguous()\n",
    "\n",
    "    # flatten the tensors\n",
    "    flat_logits=shift_logits.view(-1, shift_logits.size(-1))\n",
    "    flat_targets=shift_targets.view(-1)\n",
    "\n",
    "    # compute cross-entropy loss\n",
    "    loss = F.cross_entropy(flat_logits, flat_targets)\n",
    "    return loss\n",
    "\n",
    "logits = model(outputs.sequences[0], labels=outputs.sequences[0]).logits\n",
    "loss= compute_loss_from_logits(logits, outputs.sequences[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "91ab0c68-6180-455e-9cf5-13c80f10c971",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.0653, device='cuda:0', grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dc3edc5",
   "metadata": {},
   "source": [
    ":::{admonition} Exercise!\n",
    "\n",
    "Try a few different bits of text below, both common as well as random; what do the scores look like?  With at most 256 tokens, what's the highest score you can get? Lowest?\n",
    "\n",
    "When constructing sentences by hand, you need at least 2 tokens (so it can predict the second from the first) -- it's a good idea to insert the \"<|endoftext|>\" token at the start of the text as a 'null' character (the same token is used for the beginning of a sequence, the end of a sequence, and unknown tokens).\n",
    "\n",
    "You can see special tokens in the tokenizer by inspecting the special_tokens_map property\n",
    "```python\n",
    "tokenizer.special_tokens_map\n",
    "```\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0ba88355",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.875243663787842"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DO NOT CHANGE\n",
    "\n",
    "score_outputs(tokenizer(\"<|endoftext|>\"+\"YOUR TEXT HERE\", return_tensors='pt').to(device).input_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8e32097",
   "metadata": {},
   "source": [
    "## Text Generation and \"Improved\" Text Generation\n",
    "\n",
    "In section 5, they describe a few more potential methods to improve text generation, including:\n",
    "1. Sampling with a decaying temperature (5.1.1), and\n",
    "2. Conditioning on Internet text (5.1.2)\n",
    "\n",
    "The function below implements all of them -- the default value for 'text' is the beginning-of-sequence token, otherwise user-supplied text can be provided that will be tokenized and used as the prompt.  We've implemented a single temperature scaling method, the one used in the paper, as well as the default fixed-temperature approach.\n",
    "\n",
    "All other parameters -- including top-k and the number of new tokens -- are fixed to values from the paper.\n",
    "\n",
    ":::{admonition} Exercise\n",
    "If you're not familiar with temperature or the top-k parameter, or just need a reminder, read about it [here](https://txt.cohere.com/llm-parameters-best-outputs-language-ai/)\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "209736bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT CHANGE\n",
    "\n",
    "def gen(model, text = tokenizer.special_tokens_map['bos_token'], use_temperature_scaling=False):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\").to(device)\n",
    "    \n",
    "    if use_temperature_scaling:\n",
    "        # here we generate one token at a time starting\n",
    "        temperature_scale = np.linspace(10, 1, 20)\n",
    "        for t in temperature_scale:\n",
    "            outputs = model.generate(**inputs, do_sample=True, \n",
    "                                     max_new_tokens=1, \n",
    "                                     top_k=40,\n",
    "                                     return_dict_in_generate=True,\n",
    "                                     pad_token_id=50256,\n",
    "                                     temperature = t,\n",
    "                                    )\n",
    "            text = tokenizer.decode(outputs.sequences[0], skip_special_tokens=True)\n",
    "            inputs = tokenizer(text, return_tensors=\"pt\").to(device)\n",
    "        outputs = model.generate(**inputs, do_sample=True, \n",
    "                                 max_new_tokens=256 - len(temperature_scale), \n",
    "                                 top_k=40,\n",
    "                                 return_dict_in_generate=True,\n",
    "                                 pad_token_id=50256,\n",
    "                                 temperature = 1,\n",
    "                                )\n",
    "\n",
    "    else:\n",
    "        outputs = model.generate(**inputs, do_sample=True, \n",
    "                                 max_new_tokens=256, \n",
    "                                 top_k=40,\n",
    "                                 return_dict_in_generate=True,\n",
    "                                 output_scores = True,\n",
    "                                 pad_token_id=50256,\n",
    "                                )\n",
    "    scores = score_outputs(outputs.sequences[0], model=model)\n",
    "    return outputs.sequences[0].detach().cpu(), scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a44f986",
   "metadata": {},
   "source": [
    "## Generating Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9772e87b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49 / 50"
     ]
    }
   ],
   "source": [
    "# DO NOT CHANGE\n",
    "\n",
    "samples = []\n",
    "\n",
    "\n",
    "# in the paper they generated 200,000 samples, but ain't nobody got time for that\n",
    "N_SAMPLES = 50\n",
    "\n",
    "for sample in range(N_SAMPLES):\n",
    "    tokens, nlls = gen(model)\n",
    "    samples.append((tokens, np.mean(nlls)))\n",
    "    sys.stdout.write(f\"\\r{sample} / {N_SAMPLES}\");sys.stdout.flush"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6f2413b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT CHANGE\n",
    "\n",
    "samples.sort(key = lambda x:np.mean(x[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "61d6e70f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4503071308135986 \n",
      "With Donald Trump expected to win the election on Tuesday, there are concerns across Canada about whether Trump will make good on his pledge to bar Muslim refugees from coming to Canada.\n",
      "\n",
      "\"There is a concern at home, a bit of uneasiness and apprehension on the part of Canadians that the U.S. will indeed go down this path,\" said Chantal Hébert, a fellow of the Munk School of Global Affairs at the University of Toronto and a fellow for the Wilson Centre. \"For Canada, it would be catastrophic. For the U.S., it would actually be a positive development.\"\n",
      "\n",
      "Canadian Prime Minister Justin Trudeau says he would welcome refugees and immigrants from the U.S. But he's not convinced Donald Trump would do the same <a href=\"https://twitter.com/hashtag/cbc?src=hash\">#cbc</a> <a href=\"https://t.co/KpDZ5tH7Zi\">https://t.co/KpDZ5tH7Zi</a> —@CBCPolitics\n",
      "\n",
      "Canada accepted 25,839 refugees in 2016, the third highest number in recent history after the United States and China. Of those, 13\n",
      "+*+*+*+*+*+*+*\n",
      "1.5008273124694824 The New York Yankees are expected to sign an American League pitcher in the upcoming days, with an announcement expected later this week.\n",
      "\n",
      "Multiple outlets are reporting on reports that the Yankees are working on landing right-hander Dan Straily of the San Diego Padres.\n",
      "\n",
      "Straily, 31, is a free agent after not receiving a qualifying offer in January, making him a potential option for the Yankees.\n",
      "\n",
      "Article continues below...\n",
      "\n",
      "Straily won 15 games last season with San Diego, posting a 4.09 ERA while striking out 84 batters in 92 innings.\n",
      "\n",
      "Straily, who has a 9-7 record, 3.42 ERA and 1.32 WHIP in his career, is set to become a free agent when he has the option to become a qualifying offer. If he elects to remain with the Padres, he could become an option for the Blue Jays.\n",
      "\n",
      "The Yankees are believed to be one of several teams interested in Straily, who is likely to command a hefty contract if the Blue Jays do choose to offer him a contract.\n",
      "+*+*+*+*+*+*+*\n",
      "1.5210732221603394 The video will start in 8 Cancel\n",
      "\n",
      "Get Everton FC updates directly to your inbox Subscribe Thank you for subscribing We have more newsletters Show me See our privacy notice Could not subscribe, try again later Invalid Email\n",
      "\n",
      "Everton could be interested in Swansea City's Gylfi Sigurdsson - with the Blues looking for midfield reinforcements.\n",
      "\n",
      "The 22-year-old had been heavily linked with a move to England and had suggested he did not want to leave, but Swansea are looking to sell after they missed out on their top targets last week with Everton's deal for £36.5m for Romelu Lukaku going through.\n",
      "\n",
      "Sigurdsson wants to leave the South Wales club and Everton are prepared to offer him more than their £50,000-a-week deal and a Champions League squad for the player.\n",
      "\n",
      "Swansea have been looking at other alternative targets, including Lyon's Alexandre Lacazette, but it makes sense for them if they make offers for Sigurdsson.\n",
      "\n",
      "The Wales international is an exciting attacker who can play further forward in an attacking midfield role too, and could fit in with Roberto Martinez's plans.\n",
      "\n",
      "Romelu Lukaku in numbers Everton 1) £36m -\n",
      "+*+*+*+*+*+*+*\n"
     ]
    }
   ],
   "source": [
    "# DO NOT CHANGE\n",
    "\n",
    "for tokens, score in samples[:3]:\n",
    "    print(score, tokenizer.decode(tokens, skip_special_tokens=True))\n",
    "    print(\"+*+*+*+*+*+*+*\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08615b39",
   "metadata": {},
   "source": [
    "## Improved Scoring of Samples\n",
    "\n",
    "In addition to the simple perplexity measure, they suggest three other tools for evaluating the likelihood that a production was in the training data in section 5.2 (go read it), of which we implement two.\n",
    "\n",
    "1. Comparing to zlib compression: the model will often memorize fairly trivial strings (\"AAAAAAAAAA\") or (\"1,2,3,4,5,6,...\") -- compression is another way to approximate the 'information content' of a string.  By comparing the GPT2 perplexity to the zlib-inferred 'entropy' we can at least partially filter \"uninteresting\" samples from the data, leaving behind only samples with low perplexity but high complexity.\n",
    "\n",
    "2. Comparing to lowercased text: GPT has different tokens for uppercased and lowercased text; if it has precisely memorized a specific exact phrase, then the lower-cased version of it should me \"more unexpected\" (lower probability, higher perplexity) than the original. \n",
    "\n",
    "They also suggest evaluating perplexity on a sliding window, looking at the minimum perplexity for any subset of 50 consecutive tokens in the production.\n",
    "\n",
    ":::{admonition} Exercise!\n",
    "Using [this page](https://huggingface.co/docs/transformers/perplexity) as a reference, implement sliding window perplexity.\n",
    "\n",
    "See the [answer key](answers-4_LLM.ipynb) notebook if you get stuck.\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8bd3ebee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT CHANGE\n",
    "\n",
    "def compare_zlib(tokens, tokenizer=tokenizer):\n",
    "    base_score = score_outputs(tokens.to(device))\n",
    "    zlib_score = len(zlib.compress(tokenizer.decode(tokens, skip_special_tokens=True).encode('utf-8')))\n",
    "    return base_score / np.log2(zlib_score)\n",
    "\n",
    "def compare_lowercased(tokens, model=model, tokenizer=tokenizer):\n",
    "    test_string = tokenizer.decode(tokens, skip_special_tokens=True)\n",
    "    test_string_lower = test_string.lower()\n",
    "    inputs_lower = tokenizer(test_string_lower, return_tensors=\"pt\").to(device).input_ids\n",
    "    score = score_outputs(tokens.to(device))\n",
    "    score_lower = score_outputs(inputs_lower)\n",
    "    del inputs_lower\n",
    "    return score/score_lower"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "296a1c51",
   "metadata": {},
   "source": [
    "## Evaluation of Productions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cae2cfa5",
   "metadata": {},
   "source": [
    "With our three scoring functions, we can now score our productions from above.  For ease of analysis, we'll put them all into a single pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "101afcdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT CHANGE\n",
    "\n",
    "all_scores = list()\n",
    "\n",
    "for index, (tokens, score) in enumerate(samples):\n",
    "    td = dict()\n",
    "    td['index'] = index\n",
    "    td['text'] = tokenizer.decode(tokens)\n",
    "    td['NLL'] = score_outputs(tokens.to(device))\n",
    "    td['lower'] = compare_lowercased(tokens)\n",
    "    td['zlib'] = compare_zlib(tokens)\n",
    "    # TODO -- insert your sliding window score function here!\n",
    "    all_scores.append(td)\n",
    "results = pd.DataFrame(all_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d04a1a08",
   "metadata": {},
   "source": [
    "And now, sort by various score functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3164f055",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>text</th>\n",
       "      <th>NLL</th>\n",
       "      <th>lower</th>\n",
       "      <th>zlib</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>&lt;|endoftext|&gt;The video will start in 8 Cancel\\...</td>\n",
       "      <td>1.521073</td>\n",
       "      <td>0.619678</td>\n",
       "      <td>0.163132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>49</td>\n",
       "      <td>&lt;|endoftext|&gt;Ticketing\\n\\nAll events are hoste...</td>\n",
       "      <td>2.704234</td>\n",
       "      <td>0.679200</td>\n",
       "      <td>0.395039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>&lt;|endoftext|&gt;The official website of the TV an...</td>\n",
       "      <td>1.810654</td>\n",
       "      <td>0.696292</td>\n",
       "      <td>0.199016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>&lt;|endoftext|&gt;(JTA) — The US Embassy to France ...</td>\n",
       "      <td>1.803670</td>\n",
       "      <td>0.699413</td>\n",
       "      <td>0.194786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>&lt;|endoftext|&gt;\"I'm always being told something,...</td>\n",
       "      <td>1.836027</td>\n",
       "      <td>0.705708</td>\n",
       "      <td>0.194952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>&lt;|endoftext|&gt;The video will start in 8 Cancel\\...</td>\n",
       "      <td>1.741096</td>\n",
       "      <td>0.709982</td>\n",
       "      <td>0.188463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>&lt;|endoftext|&gt;\\nWith Donald Trump expected to w...</td>\n",
       "      <td>1.450307</td>\n",
       "      <td>0.713736</td>\n",
       "      <td>0.157522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>&lt;|endoftext|&gt;Image copyright EPA Image caption...</td>\n",
       "      <td>1.648996</td>\n",
       "      <td>0.726716</td>\n",
       "      <td>0.178218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>&lt;|endoftext|&gt;The New York Yankees are expected...</td>\n",
       "      <td>1.500827</td>\n",
       "      <td>0.746887</td>\n",
       "      <td>0.166654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>&lt;|endoftext|&gt;COPENHAGEN, Denmark (AP) — Denmar...</td>\n",
       "      <td>1.763727</td>\n",
       "      <td>0.765634</td>\n",
       "      <td>0.188794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>&lt;|endoftext|&gt;Sydney's public transport bosses ...</td>\n",
       "      <td>1.895953</td>\n",
       "      <td>0.767416</td>\n",
       "      <td>0.203833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>&lt;|endoftext|&gt;A former student of the Universit...</td>\n",
       "      <td>1.872771</td>\n",
       "      <td>0.776151</td>\n",
       "      <td>0.212022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>&lt;|endoftext|&gt;\"Puerto Rico is a part of the Uni...</td>\n",
       "      <td>1.927500</td>\n",
       "      <td>0.782142</td>\n",
       "      <td>0.207687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>&lt;|endoftext|&gt;New York Times - April 3, 1991\\n\\...</td>\n",
       "      <td>1.922341</td>\n",
       "      <td>0.785639</td>\n",
       "      <td>0.205480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>&lt;|endoftext|&gt;The number of Syrian migrants in ...</td>\n",
       "      <td>1.877062</td>\n",
       "      <td>0.792264</td>\n",
       "      <td>0.201902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>38</td>\n",
       "      <td>&lt;|endoftext|&gt;\"The only thing I can tell you is...</td>\n",
       "      <td>2.094368</td>\n",
       "      <td>0.795107</td>\n",
       "      <td>0.220649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>&lt;|endoftext|&gt;Gardaí are investigating an incid...</td>\n",
       "      <td>1.777061</td>\n",
       "      <td>0.797869</td>\n",
       "      <td>0.194058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>&lt;|endoftext|&gt;There's only one problem with tha...</td>\n",
       "      <td>1.525074</td>\n",
       "      <td>0.802986</td>\n",
       "      <td>0.165123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>&lt;|endoftext|&gt;The New Zealand police have relea...</td>\n",
       "      <td>1.956942</td>\n",
       "      <td>0.812330</td>\n",
       "      <td>0.217506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>40</td>\n",
       "      <td>&lt;|endoftext|&gt;Rio Ferdinand's goal against Chil...</td>\n",
       "      <td>2.147240</td>\n",
       "      <td>0.815593</td>\n",
       "      <td>0.230736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>30</td>\n",
       "      <td>&lt;|endoftext|&gt;It was only a matter of time befo...</td>\n",
       "      <td>2.024778</td>\n",
       "      <td>0.819804</td>\n",
       "      <td>0.217049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>&lt;|endoftext|&gt;The second-oldest surviving perso...</td>\n",
       "      <td>1.973148</td>\n",
       "      <td>0.831964</td>\n",
       "      <td>0.212028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>&lt;|endoftext|&gt;\"The first thing you are going to...</td>\n",
       "      <td>1.874478</td>\n",
       "      <td>0.834491</td>\n",
       "      <td>0.198813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>&lt;|endoftext|&gt;By By Andrew Moran Apr 30, 2015 i...</td>\n",
       "      <td>1.880974</td>\n",
       "      <td>0.849057</td>\n",
       "      <td>0.203762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>35</td>\n",
       "      <td>&lt;|endoftext|&gt;Dwight Schrute has his own \"perso...</td>\n",
       "      <td>2.071211</td>\n",
       "      <td>0.849838</td>\n",
       "      <td>0.228389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>36</td>\n",
       "      <td>&lt;|endoftext|&gt;The following is an English trans...</td>\n",
       "      <td>2.072639</td>\n",
       "      <td>0.849853</td>\n",
       "      <td>0.224235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>37</td>\n",
       "      <td>&lt;|endoftext|&gt;After a three month wait, we've f...</td>\n",
       "      <td>2.090382</td>\n",
       "      <td>0.850901</td>\n",
       "      <td>0.226624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>41</td>\n",
       "      <td>&lt;|endoftext|&gt;As the story goes, a few years ag...</td>\n",
       "      <td>2.155882</td>\n",
       "      <td>0.866194</td>\n",
       "      <td>0.233909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>42</td>\n",
       "      <td>&lt;|endoftext|&gt;Crowned with a golden tiara, the ...</td>\n",
       "      <td>2.178406</td>\n",
       "      <td>0.868713</td>\n",
       "      <td>0.231935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>&lt;|endoftext|&gt;The following article was origina...</td>\n",
       "      <td>1.769064</td>\n",
       "      <td>0.870697</td>\n",
       "      <td>0.191940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td>&lt;|endoftext|&gt;(CNN) — It was a cold and wet fal...</td>\n",
       "      <td>2.015819</td>\n",
       "      <td>0.882095</td>\n",
       "      <td>0.220010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>43</td>\n",
       "      <td>&lt;|endoftext|&gt;The National Museum of Singapore ...</td>\n",
       "      <td>2.198460</td>\n",
       "      <td>0.886139</td>\n",
       "      <td>0.234070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>&lt;|endoftext|&gt;It might just be the most bizarre...</td>\n",
       "      <td>2.005555</td>\n",
       "      <td>0.886894</td>\n",
       "      <td>0.220058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>&lt;|endoftext|&gt;As we continue to count down to t...</td>\n",
       "      <td>1.919978</td>\n",
       "      <td>0.891840</td>\n",
       "      <td>0.209723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>&lt;|endoftext|&gt;Mitt Romney's wife, Ann, is an Am...</td>\n",
       "      <td>1.930918</td>\n",
       "      <td>0.894327</td>\n",
       "      <td>0.211808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>&lt;|endoftext|&gt;In the video above, a young man i...</td>\n",
       "      <td>1.929907</td>\n",
       "      <td>0.902280</td>\n",
       "      <td>0.209780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>32</td>\n",
       "      <td>&lt;|endoftext|&gt;The world of the Internet is pret...</td>\n",
       "      <td>2.050973</td>\n",
       "      <td>0.907338</td>\n",
       "      <td>0.221833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29</td>\n",
       "      <td>&lt;|endoftext|&gt;I really wanted to write about th...</td>\n",
       "      <td>2.015845</td>\n",
       "      <td>0.909377</td>\n",
       "      <td>0.215526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>44</td>\n",
       "      <td>&lt;|endoftext|&gt;A simple app for tracking the num...</td>\n",
       "      <td>2.244637</td>\n",
       "      <td>0.921995</td>\n",
       "      <td>0.251007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>34</td>\n",
       "      <td>&lt;|endoftext|&gt;What's the best way to get the fi...</td>\n",
       "      <td>2.064318</td>\n",
       "      <td>0.927227</td>\n",
       "      <td>0.224211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>46</td>\n",
       "      <td>&lt;|endoftext|&gt;A few weeks ago, it was reported ...</td>\n",
       "      <td>2.342756</td>\n",
       "      <td>0.929404</td>\n",
       "      <td>0.259185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>33</td>\n",
       "      <td>&lt;|endoftext|&gt;It has been quite some time since...</td>\n",
       "      <td>2.052841</td>\n",
       "      <td>0.932359</td>\n",
       "      <td>0.221978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>39</td>\n",
       "      <td>&lt;|endoftext|&gt;I'm making a new, more modern \"DO...</td>\n",
       "      <td>2.102978</td>\n",
       "      <td>0.933038</td>\n",
       "      <td>0.231483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>&lt;|endoftext|&gt;I have a few things that I wanted...</td>\n",
       "      <td>1.951947</td>\n",
       "      <td>0.937084</td>\n",
       "      <td>0.215238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>45</td>\n",
       "      <td>&lt;|endoftext|&gt;The following is another video by...</td>\n",
       "      <td>2.245842</td>\n",
       "      <td>0.950267</td>\n",
       "      <td>0.240515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>47</td>\n",
       "      <td>&lt;|endoftext|&gt;I want to apologize for not being...</td>\n",
       "      <td>2.351954</td>\n",
       "      <td>0.952232</td>\n",
       "      <td>0.255116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>48</td>\n",
       "      <td>&lt;|endoftext|&gt;The federal Department of Educati...</td>\n",
       "      <td>2.485873</td>\n",
       "      <td>0.957969</td>\n",
       "      <td>0.268324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>&lt;|endoftext|&gt;There are 3 types of power.\\n\\nTh...</td>\n",
       "      <td>1.739802</td>\n",
       "      <td>0.960292</td>\n",
       "      <td>0.218728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>&lt;|endoftext|&gt;\\nThis is a simple script that wi...</td>\n",
       "      <td>1.647737</td>\n",
       "      <td>0.961835</td>\n",
       "      <td>0.184319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>31</td>\n",
       "      <td>&lt;|endoftext|&gt;Feminists and feminists of colour...</td>\n",
       "      <td>2.028336</td>\n",
       "      <td>0.976795</td>\n",
       "      <td>0.222749</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    index                                               text       NLL  \\\n",
       "2       2  <|endoftext|>The video will start in 8 Cancel\\...  1.521073   \n",
       "49     49  <|endoftext|>Ticketing\\n\\nAll events are hoste...  2.704234   \n",
       "12     12  <|endoftext|>The official website of the TV an...  1.810654   \n",
       "11     11  <|endoftext|>(JTA) — The US Embassy to France ...  1.803670   \n",
       "13     13  <|endoftext|>\"I'm always being told something,...  1.836027   \n",
       "7       7  <|endoftext|>The video will start in 8 Cancel\\...  1.741096   \n",
       "0       0  <|endoftext|>\\nWith Donald Trump expected to w...  1.450307   \n",
       "5       5  <|endoftext|>Image copyright EPA Image caption...  1.648996   \n",
       "1       1  <|endoftext|>The New York Yankees are expected...  1.500827   \n",
       "8       8  <|endoftext|>COPENHAGEN, Denmark (AP) — Denmar...  1.763727   \n",
       "18     18  <|endoftext|>Sydney's public transport bosses ...  1.895953   \n",
       "14     14  <|endoftext|>A former student of the Universit...  1.872771   \n",
       "21     21  <|endoftext|>\"Puerto Rico is a part of the Uni...  1.927500   \n",
       "20     20  <|endoftext|>New York Times - April 3, 1991\\n\\...  1.922341   \n",
       "16     16  <|endoftext|>The number of Syrian migrants in ...  1.877062   \n",
       "38     38  <|endoftext|>\"The only thing I can tell you is...  2.094368   \n",
       "10     10  <|endoftext|>Gardaí are investigating an incid...  1.777061   \n",
       "3       3  <|endoftext|>There's only one problem with tha...  1.525074   \n",
       "25     25  <|endoftext|>The New Zealand police have relea...  1.956942   \n",
       "40     40  <|endoftext|>Rio Ferdinand's goal against Chil...  2.147240   \n",
       "30     30  <|endoftext|>It was only a matter of time befo...  2.024778   \n",
       "26     26  <|endoftext|>The second-oldest surviving perso...  1.973148   \n",
       "15     15  <|endoftext|>\"The first thing you are going to...  1.874478   \n",
       "17     17  <|endoftext|>By By Andrew Moran Apr 30, 2015 i...  1.880974   \n",
       "35     35  <|endoftext|>Dwight Schrute has his own \"perso...  2.071211   \n",
       "36     36  <|endoftext|>The following is an English trans...  2.072639   \n",
       "37     37  <|endoftext|>After a three month wait, we've f...  2.090382   \n",
       "41     41  <|endoftext|>As the story goes, a few years ag...  2.155882   \n",
       "42     42  <|endoftext|>Crowned with a golden tiara, the ...  2.178406   \n",
       "9       9  <|endoftext|>The following article was origina...  1.769064   \n",
       "28     28  <|endoftext|>(CNN) — It was a cold and wet fal...  2.015819   \n",
       "43     43  <|endoftext|>The National Museum of Singapore ...  2.198460   \n",
       "27     27  <|endoftext|>It might just be the most bizarre...  2.005555   \n",
       "19     19  <|endoftext|>As we continue to count down to t...  1.919978   \n",
       "23     23  <|endoftext|>Mitt Romney's wife, Ann, is an Am...  1.930918   \n",
       "22     22  <|endoftext|>In the video above, a young man i...  1.929907   \n",
       "32     32  <|endoftext|>The world of the Internet is pret...  2.050973   \n",
       "29     29  <|endoftext|>I really wanted to write about th...  2.015845   \n",
       "44     44  <|endoftext|>A simple app for tracking the num...  2.244637   \n",
       "34     34  <|endoftext|>What's the best way to get the fi...  2.064318   \n",
       "46     46  <|endoftext|>A few weeks ago, it was reported ...  2.342756   \n",
       "33     33  <|endoftext|>It has been quite some time since...  2.052841   \n",
       "39     39  <|endoftext|>I'm making a new, more modern \"DO...  2.102978   \n",
       "24     24  <|endoftext|>I have a few things that I wanted...  1.951947   \n",
       "45     45  <|endoftext|>The following is another video by...  2.245842   \n",
       "47     47  <|endoftext|>I want to apologize for not being...  2.351954   \n",
       "48     48  <|endoftext|>The federal Department of Educati...  2.485873   \n",
       "6       6  <|endoftext|>There are 3 types of power.\\n\\nTh...  1.739802   \n",
       "4       4  <|endoftext|>\\nThis is a simple script that wi...  1.647737   \n",
       "31     31  <|endoftext|>Feminists and feminists of colour...  2.028336   \n",
       "\n",
       "       lower      zlib  \n",
       "2   0.619678  0.163132  \n",
       "49  0.679200  0.395039  \n",
       "12  0.696292  0.199016  \n",
       "11  0.699413  0.194786  \n",
       "13  0.705708  0.194952  \n",
       "7   0.709982  0.188463  \n",
       "0   0.713736  0.157522  \n",
       "5   0.726716  0.178218  \n",
       "1   0.746887  0.166654  \n",
       "8   0.765634  0.188794  \n",
       "18  0.767416  0.203833  \n",
       "14  0.776151  0.212022  \n",
       "21  0.782142  0.207687  \n",
       "20  0.785639  0.205480  \n",
       "16  0.792264  0.201902  \n",
       "38  0.795107  0.220649  \n",
       "10  0.797869  0.194058  \n",
       "3   0.802986  0.165123  \n",
       "25  0.812330  0.217506  \n",
       "40  0.815593  0.230736  \n",
       "30  0.819804  0.217049  \n",
       "26  0.831964  0.212028  \n",
       "15  0.834491  0.198813  \n",
       "17  0.849057  0.203762  \n",
       "35  0.849838  0.228389  \n",
       "36  0.849853  0.224235  \n",
       "37  0.850901  0.226624  \n",
       "41  0.866194  0.233909  \n",
       "42  0.868713  0.231935  \n",
       "9   0.870697  0.191940  \n",
       "28  0.882095  0.220010  \n",
       "43  0.886139  0.234070  \n",
       "27  0.886894  0.220058  \n",
       "19  0.891840  0.209723  \n",
       "23  0.894327  0.211808  \n",
       "22  0.902280  0.209780  \n",
       "32  0.907338  0.221833  \n",
       "29  0.909377  0.215526  \n",
       "44  0.921995  0.251007  \n",
       "34  0.927227  0.224211  \n",
       "46  0.929404  0.259185  \n",
       "33  0.932359  0.221978  \n",
       "39  0.933038  0.231483  \n",
       "24  0.937084  0.215238  \n",
       "45  0.950267  0.240515  \n",
       "47  0.952232  0.255116  \n",
       "48  0.957969  0.268324  \n",
       "6   0.960292  0.218728  \n",
       "4   0.961835  0.184319  \n",
       "31  0.976795  0.222749  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DO NOT CHANGE\n",
    "\n",
    "results.sort_values('lower')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67382668",
   "metadata": {},
   "source": [
    ":::{exercise}\n",
    "Examine the outputs with respect to different scoring systems.  Do they at least look plausible as potential candidates for memorized text?  Which scoring system seems to perform the best?\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "375dd105",
   "metadata": {},
   "source": [
    ":::{exercise}\n",
    "Perform this attack against one of the fine-tuned models from the previous labs -- instructions on loading them are in lab 1 -- where we know what the instruction dataset looked like. Can you recover any training samples?\n",
    "\n",
    "NB: these models are very small and poor at memorization; don't be disappointed if you get borderline poor results.\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3052e05b",
   "metadata": {},
   "source": [
    ":::{exercise}\n",
    "Modify the attack to try to recover specific bits of information: \n",
    "1. Find (or make up) a fixed text prompt that is a prefix to the information you want to try to recover\n",
    "2. Generate a large number of samples using the method above\n",
    "3. Score, sort/filter, and check the results.\n",
    "\n",
    "Things to explore:\n",
    "- shorter or longer prompts\n",
    "- temperature scaling\n",
    "- computing other scoring functions that sample perplexity over a window\n",
    "\n",
    "And one last reminder: GPT2-large is (name aside) a relatively small model; the amount of memorized data is likely to be low.  If you have time, you may wish to try loading the 'gpt2-xl' model -- this is the \"full\" GPT-2 model used in the paper, however it is significantly slower to use.  Also remember that the authors took the top 1,000 samples from 200,000 for each condition, so the total volume we examine here is much smaller simply due to time (but you can do this at home too!)\n",
    "\n",
    "Please share any interesting findings with us!\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e182ded5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49 / 50"
     ]
    }
   ],
   "source": [
    "# provided code\n",
    "\n",
    "samples = []\n",
    "\n",
    "# in the paper they generated 200,000 samples, but ain't nobody got time for that\n",
    "N_SAMPLES = 50\n",
    "\n",
    "for sample in range(N_SAMPLES):\n",
    "    tokens, nlls = gen(model, text = \"YOUR PROMPT HERE\", use_temperature_scaling=True)\n",
    "    samples.append((tokens, np.mean(nlls)))\n",
    "    sys.stdout.write(f\"\\r{sample} / {N_SAMPLES}\");sys.stdout.flush"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52efbc42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT CHANGE\n",
    "\n",
    "print(tokenizer.decode(gen(model, text=\"The Ventura county DMV is located\")[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd2a2d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT CHANGE\n",
    "\n",
    "all_scores = list()\n",
    "\n",
    "for index, (tokens, score) in enumerate(samples):\n",
    "    td = dict()\n",
    "    td['index'] = index\n",
    "    td['text'] = tokenizer.decode(tokens)\n",
    "    td['NLL'] = score_outputs(tokens.to(device))\n",
    "    td['lower'] = compare_lowercased(tokens)\n",
    "    td['zlib'] = compare_zlib(tokens)\n",
    "    # TODO -- insert your sliding window score function here!\n",
    "    all_scores.append(td)\n",
    "results = pd.DataFrame(all_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25a3d978",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT CHANGE\n",
    "\n",
    "results.sort_values('lower')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9812d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT CHANGE\n",
    "\n",
    "# to view a specific row from a dataframe, use 'iloc' (index location)\n",
    "results.iloc[12].text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab2e7d3c-b6ca-4cfe-ad9c-0fe6aa328d45",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "Were you able to follow the paper? \n",
    "Did you identify any training data? Can you verify somehow that that data was actually in the training set?  Names, phone numbers, and addresses of businesses or government offices are all good test cases for models like this.  While this kind of attack can be difficult and expensive to execute, the potential risks to the model owner can be severe if the model exposes any sort of regulated or GDPR-sensitive content.  This kind of attack can also be used as a training data set inference attack: if you prime the model with several strings that are in a known dataset (such as the \"Colossal Cleaned Common Crawl\" aka C4 dataset: https://huggingface.co/datasets/allenai/c4/tree/main) and find that many of the complete samples can be recovered, then you've got more confidence that that dataset was used in training the model, which can help you execute other attacks such as training a proxy model.\n",
    "\n",
    "This is the end of the labs; congratulations, you made it! If you have time, we encourage you to go back and experiment with this or other attacks, as well as to download any notebooks, code, or models that you want to take with you.  Thank you so much for taking this class with us, and as always, please let us know if you have any questions, comments, or suggestions for next time. Thank you!\n",
    "\n",
    "If you'd like to try the assessment to get a certificate, **move on to the [assessment overview notebook](../8_course_assessment/1_assessment_intro.ipynb)**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "591dd1f6",
   "metadata": {},
   "source": [
    "![DLI Logo](../assets/DLI_Header.png)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
