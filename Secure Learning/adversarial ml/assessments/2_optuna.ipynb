{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "649d23d5",
   "metadata": {},
   "source": [
    "![DLI Logo](../assets/DLI_Header.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cebb4bee",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "In this module, you will learn how to think about machine learning problems and attacks as **optimizations** and we'll introduce a new tool: [Optuna](https://optuna.org/).\n",
    "\n",
    "## Learning Objectives:\n",
    "1. Apply `Optuna` to optimize attack hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab69fded",
   "metadata": {},
   "source": [
    "# Optimize\n",
    "We've reached a crucial milestone and we're about to come full circle on a whole load of concepts. We ended the previous section lamenting that there are entirely too many techniques to know which is best. Even if you knew which algorithm was best for your situation, there are _still_ hyperparameters to choose. We've conveniently hand-waved explaining hyperparameters in any real detail in anticipation of this lab. Rather than optimize a model (for which there are several references), we're going to optimize our attacks using Optuna.\n",
    "\n",
    "Optuna is an open-source hyperparameter optimization (HPO) framework, which is designed to optimize machine learning model parameters. It's normally used to automate the process of finding the best set of hyperparameters for a model. Recall that hypterparameters are typically the \"fixed\" values of an algorithm that define behavior or constraints (like a distance metric) it needs to work within. Optuna basically builds another model using Bayesian optimization techniques to infer the optimal values.\n",
    "\n",
    "1. **Define a Prior**: This is an initial assumption about the function. \n",
    "2. **Collect Data and Update the Prior**: This involves evaluating the actual function at certain points, and then using this data to update our prior belief about the function. This updated belief is called the posterior, and it represents a kind of best guess at what the function looks like, given the current data.\n",
    "3. **Choose the Next Point to Evaluate**: After updating the posterior, we need to decide where to evaluate the function next. This is done by applying an acquisition function to the posterior. The acquisition function trades off exploration (testing areas where we are uncertain about the function) and exploitation (focusing on areas where the function seems high). Common choices for the acquisition function include `Expected Improvement`, `Probability of Improvement`, and `Upper Confidence Bound`.\n",
    "4. **Iterate**: Steps 2 and 3 are then repeated.\n",
    "\n",
    "The goal of using Optuna (and HPO in general) is to find the set of hyperparameters that will result in the best performance for a given machine learning model, based on a specified evaluation metric. This process involves defining a space of possible hyperparameters and then systematically exploring this space, typically through multiple `trials`. An advantage of Bayesian Optimization is that it doesn't require any derivatives (gradients) of the function, which makes it suitable for optimizing \"Blackbox\" functions. It's perhaps best to think of Optuna as an optimizer of processes, rather than data. \n",
    "\n",
    "In this lab we're going to revisit work from previous labs and apply optimization techniques to make them _better_. \n",
    "\n",
    "\n",
    "# Imports and Model\n",
    "We'll start by importing everything we need at the top and loading our target model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ef693228-990a-4ce2-921c-fef855c5c08a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting optuna\n",
      "  Downloading optuna-4.1.0-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting alembic>=1.5.0 (from optuna)\n",
      "  Downloading alembic-1.14.0-py3-none-any.whl.metadata (7.4 kB)\n",
      "Collecting colorlog (from optuna)\n",
      "  Downloading colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\usuario\\anaconda3\\envs\\redai\\lib\\site-packages (from optuna) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\usuario\\anaconda3\\envs\\redai\\lib\\site-packages (from optuna) (24.1)\n",
      "Requirement already satisfied: sqlalchemy>=1.4.2 in c:\\users\\usuario\\anaconda3\\envs\\redai\\lib\\site-packages (from optuna) (2.0.28)\n",
      "Requirement already satisfied: tqdm in c:\\users\\usuario\\anaconda3\\envs\\redai\\lib\\site-packages (from optuna) (4.66.4)\n",
      "Requirement already satisfied: PyYAML in c:\\users\\usuario\\anaconda3\\envs\\redai\\lib\\site-packages (from optuna) (6.0.1)\n",
      "Collecting Mako (from alembic>=1.5.0->optuna)\n",
      "  Downloading Mako-1.3.8-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: typing-extensions>=4 in c:\\users\\usuario\\anaconda3\\envs\\redai\\lib\\site-packages (from alembic>=1.5.0->optuna) (4.12.2)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\usuario\\anaconda3\\envs\\redai\\lib\\site-packages (from sqlalchemy>=1.4.2->optuna) (3.0.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\usuario\\anaconda3\\envs\\redai\\lib\\site-packages (from colorlog->optuna) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in c:\\users\\usuario\\anaconda3\\envs\\redai\\lib\\site-packages (from Mako->alembic>=1.5.0->optuna) (2.1.5)\n",
      "Downloading optuna-4.1.0-py3-none-any.whl (364 kB)\n",
      "   ---------------------------------------- 0.0/364.4 kB ? eta -:--:--\n",
      "   - -------------------------------------- 10.2/364.4 kB ? eta -:--:--\n",
      "   --- ----------------------------------- 30.7/364.4 kB 660.6 kB/s eta 0:00:01\n",
      "   --------- ----------------------------- 92.2/364.4 kB 751.6 kB/s eta 0:00:01\n",
      "   -------------- ----------------------- 143.4/364.4 kB 853.3 kB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 266.2/364.4 kB 1.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 364.4/364.4 kB 1.4 MB/s eta 0:00:00\n",
      "Downloading alembic-1.14.0-py3-none-any.whl (233 kB)\n",
      "   ---------------------------------------- 0.0/233.5 kB ? eta -:--:--\n",
      "   ---------------------------------------- 233.5/233.5 kB 7.2 MB/s eta 0:00:00\n",
      "Downloading colorlog-6.9.0-py3-none-any.whl (11 kB)\n",
      "Downloading Mako-1.3.8-py3-none-any.whl (78 kB)\n",
      "   ---------------------------------------- 0.0/78.6 kB ? eta -:--:--\n",
      "   ---------------------------------------- 78.6/78.6 kB ? eta 0:00:00\n",
      "Installing collected packages: Mako, colorlog, alembic, optuna\n",
      "Successfully installed Mako-1.3.8 alembic-1.14.0 colorlog-6.9.0 optuna-4.1.0\n"
     ]
    }
   ],
   "source": [
    "!pip install optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "054426c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# DO NOT CHANGE\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "from libs.controls import modifier\n",
    "\n",
    "import optuna\n",
    "import torch\n",
    "import numpy as np\n",
    "import zipfile\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "\n",
    "from art.estimators.classification import BlackBoxClassifierNeuralNetwork\n",
    "from art.utils import compute_success\n",
    "from art.attacks.evasion import SimBA\n",
    "from torch.nn.functional import softmax\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2b691935",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT CHANGE\n",
    "\n",
    "target_model = torch.hub.load('pytorch/vision:v0.10.0', 'mobilenet_v2', weights='MobileNet_V2_Weights.DEFAULT', verbose=False)\n",
    "target_model.eval()\n",
    "target_model.to(device);\n",
    "\n",
    "# Define the transforms for preprocessing\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize(256), \n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    )\n",
    "]);\n",
    "\n",
    "unnormalize = transforms.Normalize(\n",
    "   mean= [-m/s for m, s in zip([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])],\n",
    "   std= [1/s for s in [0.229, 0.224, 0.225]]\n",
    ")\n",
    "\n",
    "with open(\"../data/labels.txt\", 'r') as f:\n",
    "    labels = [label.strip() for label in f.readlines()]\n",
    "\n",
    "img = Image.open(\"../data/dog.jpg\")\n",
    "img_tensor = preprocess(img).unsqueeze(0)\n",
    "unnormed_img_tensor = unnormalize(img_tensor).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "365ea198",
   "metadata": {},
   "source": [
    "# Optuna\n",
    "Optuna is easy to use, here is how we setup an optimization problem. We'll use a toy example where we want to find the minimum of the function $(x-2)^2$.  The true answer is $x=2$, but Optuna doesn't know that and will need to sample the space we define and and infer the answer from the examples it creates.\n",
    "\n",
    "First we define an `objective` function.  Think of this like a loss function. Here we want to minimize the squared difference between $x$ and $2$.  We'll define the sample space as the float range $-10<x<10$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8881449f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT CHANGE\n",
    "\n",
    "def objective(trial):\n",
    "    x = trial.suggest_float('x', -10, 10)\n",
    "    return (x - 2) ** 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15f77ef3",
   "metadata": {},
   "source": [
    "Then we create a \"study\". `create_study` provides an entry point to create and configure a `Study` instance, which then gets passed to `optimize` (and other functions to carry out the tuning process). When you call `optimize` on the `Study`, the `Study` manages the full optimization loop internally, leveraging the Study's samplers and algorithms to effectively search the hyperparameter space. Then, after `n_trials` have been completed, Optuna will have the \"best\" parameters from within the tested range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "98c6ecf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-31 12:48:24,807] A new study created in memory with name: no-name-20918f5f-be72-46f7-b3e6-c7ad8573cf1a\n"
     ]
    }
   ],
   "source": [
    "# DO NOT CHANGE\n",
    "\n",
    "study = optuna.create_study()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "50c8615b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-31 12:48:59,739] Trial 0 finished with value: 86.05116463939666 and parameters: {'x': -7.27637669779514}. Best is trial 0 with value: 86.05116463939666.\n",
      "[I 2024-12-31 12:48:59,741] Trial 1 finished with value: 50.08658034588245 and parameters: {'x': -5.077187318835248}. Best is trial 1 with value: 50.08658034588245.\n",
      "[I 2024-12-31 12:48:59,741] Trial 2 finished with value: 122.72900360369016 and parameters: {'x': -9.07831230845611}. Best is trial 1 with value: 50.08658034588245.\n",
      "[I 2024-12-31 12:48:59,741] Trial 3 finished with value: 14.081863161429293 and parameters: {'x': 5.752580866740821}. Best is trial 3 with value: 14.081863161429293.\n",
      "[I 2024-12-31 12:48:59,741] Trial 4 finished with value: 47.397117769063584 and parameters: {'x': -4.884556468579772}. Best is trial 3 with value: 14.081863161429293.\n",
      "[I 2024-12-31 12:48:59,741] Trial 5 finished with value: 10.661918081258833 and parameters: {'x': 5.265259267081074}. Best is trial 5 with value: 10.661918081258833.\n",
      "[I 2024-12-31 12:48:59,741] Trial 6 finished with value: 129.78306641261238 and parameters: {'x': -9.392237111849997}. Best is trial 5 with value: 10.661918081258833.\n",
      "[I 2024-12-31 12:48:59,741] Trial 7 finished with value: 1.9291521679984367 and parameters: {'x': 0.6110607759882232}. Best is trial 7 with value: 1.9291521679984367.\n",
      "[I 2024-12-31 12:48:59,741] Trial 8 finished with value: 5.568087925939841 and parameters: {'x': 4.359679623580252}. Best is trial 7 with value: 1.9291521679984367.\n",
      "[I 2024-12-31 12:48:59,741] Trial 9 finished with value: 84.61250099355267 and parameters: {'x': -7.198505367370977}. Best is trial 7 with value: 1.9291521679984367.\n",
      "[I 2024-12-31 12:48:59,763] Trial 10 finished with value: 3.734581234656391 and parameters: {'x': 0.06749353567539373}. Best is trial 7 with value: 1.9291521679984367.\n",
      "[I 2024-12-31 12:48:59,772] Trial 11 finished with value: 3.188199102664597 and parameters: {'x': 0.21444711569088581}. Best is trial 7 with value: 1.9291521679984367.\n",
      "[I 2024-12-31 12:48:59,778] Trial 12 finished with value: 3.28292707598348 and parameters: {'x': 0.18811504891080888}. Best is trial 7 with value: 1.9291521679984367.\n",
      "[I 2024-12-31 12:48:59,787] Trial 13 finished with value: 50.44880677441431 and parameters: {'x': 9.102732345683195}. Best is trial 7 with value: 1.9291521679984367.\n",
      "[I 2024-12-31 12:48:59,793] Trial 14 finished with value: 16.516445816499168 and parameters: {'x': -2.06404303821935}. Best is trial 7 with value: 1.9291521679984367.\n",
      "[I 2024-12-31 12:48:59,798] Trial 15 finished with value: 0.22292544047898008 and parameters: {'x': 2.4721498072423413}. Best is trial 15 with value: 0.22292544047898008.\n",
      "[I 2024-12-31 12:48:59,804] Trial 16 finished with value: 0.0232842077396704 and parameters: {'x': 2.1525916371878564}. Best is trial 16 with value: 0.0232842077396704.\n",
      "[I 2024-12-31 12:48:59,809] Trial 17 finished with value: 1.1750918285360539 and parameters: {'x': 3.0840165259515437}. Best is trial 16 with value: 0.0232842077396704.\n",
      "[I 2024-12-31 12:48:59,814] Trial 18 finished with value: 39.26675660879285 and parameters: {'x': 8.266319223339396}. Best is trial 16 with value: 0.0232842077396704.\n",
      "[I 2024-12-31 12:48:59,820] Trial 19 finished with value: 0.42456305524214444 and parameters: {'x': 2.6515850330096176}. Best is trial 16 with value: 0.0232842077396704.\n"
     ]
    }
   ],
   "source": [
    "# DO NOT CHANGE\n",
    "\n",
    "# Run the objective n_trials times to optimize\n",
    "study.optimize(objective, n_trials=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9826168-5a7d-43c1-867c-f3059c801b5d",
   "metadata": {},
   "source": [
    "Let's see how well Optuna did finding the minimum.  You can run the cell above with more `n_trials` to get closer to the true minimum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "64debf99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params::\n",
      "---------------\n",
      "{'x': 2.1525916371878564}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# DO NOT CHANGE\n",
    "\n",
    "print(f\"Best params::\\n---------------\\n{study.best_params}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a45b5d6f",
   "metadata": {},
   "source": [
    "By default, Optuna uses Tree-Parzen Estimator (TPE), a sequential model-based optimization (SMBO) approach that builds a probabilistic model of the objective function to suggest new parameters. TPE specifically models $P(x|y)$ and $P(y)$ where $x$ represents parameters and $y$ is the associated cost. The Bayesian base of this algorithm means it becomes better at selecting parameters as the number of trials increase. \n",
    "\n",
    "- **Initialization**: Start with initial random samples from the defined space and their corresponding objective function values.\n",
    "- **Model building**: Using the collected data, build two probability models, `l(x)` for parameters that improved the model's performance and `g(x)` for parameters that did not improve. The model used to estimate these probabilities.\n",
    "- **Suggestion**: For the next round, suggest new hyperparameters to try. This is based on calculating the Expected Improvement (EI) over the current best parameters, where the EI of a set of hyperparameters is proportional to the ratio `l(x) / g(x)`. This suggests that we prefer regions of the space where good hyperparameters are more likely than bad ones according to the model.\n",
    "- **Iteration**: Evaluate the objective function with the new parameters, update the models, and repeat from step 2. Over time, the TPE algorithm should hone in on the best parameters.\n",
    "\n",
    "The primary of advantages of TPE (and other SMBO techniques) is that it can handle both continuous and discrete hyperparameters, and it doesn't require the objective function to be differentiable (as gradient-based methods do)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10069850",
   "metadata": {},
   "source": [
    "# Optimize an Attack\n",
    "First, we'll bring forward ART and write a `predict` function for the attack to use. Then we build the attack as before. One thing you may notice is instead of `BlackBoxClassifier`, we now have `BlackBoxClassifierNeuralNetwork`. This is because we're using `SimBA` which requires probabilities and ART is reasonably strict about what is need upfront before you can start running an attack."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6f4a3483",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT CHANGE\n",
    "\n",
    "class ModelWrapper: \n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def predict(self, x):\n",
    "        torch_tensor = torch.from_numpy(x).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            output = target_model(torch_tensor)        \n",
    "        probs = torch.softmax(output, dim=1).cpu().numpy()\n",
    "        return probs\n",
    "\n",
    "model_wrapper = ModelWrapper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ab52aa04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT CHANGE\n",
    "\n",
    "classifier = BlackBoxClassifierNeuralNetwork(\n",
    "    predict_fn = lambda x:model_wrapper.predict(x),\n",
    "    nb_classes = len(labels),\n",
    "    input_shape = img_tensor[0].shape\n",
    ")\n",
    "\n",
    "attack = SimBA(classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5a08f37b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attack params\n",
      "---------------\n",
      "attack: dct\n",
      "max_iter: 3000\n",
      "epsilon: 0.1\n",
      "order: random\n",
      "freq_dim: 4\n",
      "stride: 1\n",
      "targeted: None\n",
      "batch_size: 1\n",
      "verbose: True\n"
     ]
    }
   ],
   "source": [
    "# DO NOT CHANGE\n",
    "\n",
    "print(\"Attack params\\n---------------\")\n",
    "[print(f\"{i}: {attack.__dict__.get(i)}\") for i in attack.attack_params];"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac5b8c9e-153a-408f-829c-dbd36eed18fd",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca97677b",
   "metadata": {},
   "source": [
    "This is the part we've failed to mention - don't be mad. `SimBA` (and pretty much all attacks) have default hyperparameters that are set when the attack is created. However, these values are default, and we're not confident where they came from or the assumptions made when these values were chosen. We've learned that manually coming up the reasonable values is futile. So here we are, using yet another optimization technique to make a number go arbitrarily up or down. If you've managed to run into a certain `batch_size` and never figured it out; here is the answer to why `1` sample went to `64` samples in your `predict` functions in ART. \n",
    "\n",
    "Let's wrap our attack with Optuna and define what we want to minimize in our attack. In this case, we want to minimize `l2_norm`.  \n",
    "\n",
    "Here we write an objective function that runs a chosen `attack` (SimBA). As we're not giving Optuna any variables or suggested ranges, it won't optimize anything yet. \n",
    "\n",
    "You will see all the parameter values it chose (just an empty set for now) and the result of the `trial`, before printing the best parameters (none yet) at the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "36ac0ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT CHANGE\n",
    "\n",
    "def objective(trial, attack, x):\n",
    "    with torch.no_grad():\n",
    "        results = attack.generate(x=x)\n",
    "        \n",
    "    l2_norm = torch.norm(img_tensor - results, p=2).float()\n",
    "\n",
    "    return l2_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f7c46edd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-31 14:18:23,973] A new study created in memory with name: no-name-072e1180-9d04-4388-939a-629643d6b686\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70eced2be1614719bcb10797ea3bf454",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93ffaa645c8f4db7b1d9a9058128f042",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "SimBA - sample:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2024-12-31 14:21:12,788] Trial 0 finished with value: 4.8764729499816895 and parameters: {}. Best is trial 0 with value: 4.8764729499816895.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6fdb7c0d0e74f93ab442217cccff4ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "SimBA - sample:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2024-12-31 14:22:32,135] Trial 1 finished with value: 4.84870719909668 and parameters: {}. Best is trial 1 with value: 4.84870719909668.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0959a790e6794b9b8bc9a77ca8e3bfb5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "SimBA - sample:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2024-12-31 14:23:43,746] Trial 2 finished with value: 4.823896408081055 and parameters: {}. Best is trial 2 with value: 4.823896408081055.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f62869d50816413ab3705919797d6430",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "SimBA - sample:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2024-12-31 14:24:59,007] Trial 3 finished with value: 4.857980251312256 and parameters: {}. Best is trial 2 with value: 4.823896408081055.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dad0e4c62a4d4fb89af54dd4e3d6c455",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "SimBA - sample:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2024-12-31 14:26:09,750] Trial 4 finished with value: 4.855921268463135 and parameters: {}. Best is trial 2 with value: 4.823896408081055.\n",
      "\n",
      "Best params::\n",
      "---------------\n",
      "{}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# DO NOT CHANGE\n",
    "\n",
    "study = optuna.create_study()\n",
    "study.optimize(\n",
    "    lambda trial: objective(trial, attack=attack, x=img_tensor.numpy()), \n",
    "    n_trials=5, show_progress_bar=True\n",
    ");\n",
    "\n",
    "print(f\"\\nBest params::\\n---------------\\n{study.best_params}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a61d7a8",
   "metadata": {},
   "source": [
    "The same result every time - this is a good baseline to start experimenting with. Now you have mechanics down, lets minimize this `L2` distance metric. Here we update the `objective` function to\n",
    "\n",
    "1. Give Optuna access to the attack parameters. Ranges for the paramaters here are arbitrarily chosen to bracket the default attack hyperparameters we exposed earlier.\n",
    "2. Update the attack with the new parameters \n",
    "3. Execute the attack\n",
    "4. Return the L2 distance between the original image and the adversarial image. This is what we want to minimize (arbitrarily)\n",
    "\n",
    "We hope to see is the `L2` distance going down..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1073c65e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-31 21:18:38,888] A new study created in memory with name: no-name-82f13d75-9332-46f9-9bcd-bf5a3132f7f1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df0504efe77d4928b7b0499ade68ecbe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2024-12-31 21:18:53,414] Trial 0 finished with value: 13.587656021118164 and parameters: {'max_iter': 2680, 'epsilon': 0.7102382794616912, 'freq_dim': 19}. Best is trial 0 with value: 13.587656021118164.\n",
      "[I 2024-12-31 21:19:06,519] Trial 1 finished with value: 13.454999923706055 and parameters: {'max_iter': 795, 'epsilon': 0.7286295376939307, 'freq_dim': 20}. Best is trial 1 with value: 13.454999923706055.\n",
      "[I 2024-12-31 21:19:23,672] Trial 2 finished with value: 14.701762199401855 and parameters: {'max_iter': 2098, 'epsilon': 0.7454095409339343, 'freq_dim': 16}. Best is trial 1 with value: 13.454999923706055.\n",
      "[I 2024-12-31 21:19:29,205] Trial 3 finished with value: 2.47544264793396 and parameters: {'max_iter': 202, 'epsilon': 0.185023456459997, 'freq_dim': 18}. Best is trial 3 with value: 2.47544264793396.\n",
      "[I 2024-12-31 21:20:02,031] Trial 4 finished with value: 9.494013786315918 and parameters: {'max_iter': 1716, 'epsilon': 0.3416973758598291, 'freq_dim': 10}. Best is trial 3 with value: 2.47544264793396.\n",
      "[I 2024-12-31 21:20:31,469] Trial 5 finished with value: 10.375703811645508 and parameters: {'max_iter': 1669, 'epsilon': 0.3731883298793364, 'freq_dim': 3}. Best is trial 3 with value: 2.47544264793396.\n",
      "[I 2024-12-31 21:20:42,295] Trial 6 finished with value: 13.748163223266602 and parameters: {'max_iter': 1977, 'epsilon': 0.7661554857474538, 'freq_dim': 15}. Best is trial 3 with value: 2.47544264793396.\n",
      "[I 2024-12-31 21:21:35,520] Trial 7 finished with value: 3.974780797958374 and parameters: {'max_iter': 2204, 'epsilon': 0.09421140072072476, 'freq_dim': 14}. Best is trial 3 with value: 2.47544264793396.\n",
      "[I 2024-12-31 21:22:25,628] Trial 8 finished with value: 5.049009323120117 and parameters: {'max_iter': 2105, 'epsilon': 0.12595008711299158, 'freq_dim': 19}. Best is trial 3 with value: 2.47544264793396.\n",
      "[I 2024-12-31 21:22:44,009] Trial 9 finished with value: 11.584851264953613 and parameters: {'max_iter': 1761, 'epsilon': 0.5196519171522357, 'freq_dim': 18}. Best is trial 3 with value: 2.47544264793396.\n",
      "[I 2024-12-31 21:22:48,277] Trial 10 finished with value: 10.429330825805664 and parameters: {'max_iter': 144, 'epsilon': 0.9943985158128675, 'freq_dim': 9}. Best is trial 3 with value: 2.47544264793396.\n",
      "[I 2024-12-31 21:23:12,853] Trial 11 finished with value: 0.05801684036850929 and parameters: {'max_iter': 939, 'epsilon': 0.00191272620177807, 'freq_dim': 14}. Best is trial 11 with value: 0.05801684036850929.\n",
      "[I 2024-12-31 21:23:34,190] Trial 12 finished with value: 1.0989683866500854 and parameters: {'max_iter': 881, 'epsilon': 0.037628040338579805, 'freq_dim': 12}. Best is trial 11 with value: 0.05801684036850929.\n",
      "[I 2024-12-31 21:23:59,056] Trial 13 finished with value: 0.35056760907173157 and parameters: {'max_iter': 1010, 'epsilon': 0.011102517689636271, 'freq_dim': 7}. Best is trial 11 with value: 0.05801684036850929.\n",
      "[I 2024-12-31 21:24:26,493] Trial 14 finished with value: 0.0717543438076973 and parameters: {'max_iter': 1116, 'epsilon': 0.002160536830909222, 'freq_dim': 6}. Best is trial 11 with value: 0.05801684036850929.\n",
      "[I 2024-12-31 21:24:56,129] Trial 15 finished with value: 7.780753135681152 and parameters: {'max_iter': 1242, 'epsilon': 0.2651676067383488, 'freq_dim': 4}. Best is trial 11 with value: 0.05801684036850929.\n",
      "[I 2024-12-31 21:25:06,929] Trial 16 finished with value: 9.0376615524292 and parameters: {'max_iter': 438, 'epsilon': 0.49085886795898426, 'freq_dim': 6}. Best is trial 11 with value: 0.05801684036850929.\n",
      "[I 2024-12-31 21:25:38,614] Trial 17 finished with value: 7.079156398773193 and parameters: {'max_iter': 1304, 'epsilon': 0.23077419990290834, 'freq_dim': 1}. Best is trial 11 with value: 0.05801684036850929.\n",
      "[I 2024-12-31 21:25:55,073] Trial 18 finished with value: 0.5015320181846619 and parameters: {'max_iter': 631, 'epsilon': 0.020142057153256752, 'freq_dim': 12}. Best is trial 11 with value: 0.05801684036850929.\n",
      "[I 2024-12-31 21:26:15,045] Trial 19 finished with value: 11.384517669677734 and parameters: {'max_iter': 1231, 'epsilon': 0.4793746818577161, 'freq_dim': 7}. Best is trial 11 with value: 0.05801684036850929.\n",
      "[I 2024-12-31 21:26:28,062] Trial 20 finished with value: 3.271127462387085 and parameters: {'max_iter': 527, 'epsilon': 0.15088606574818805, 'freq_dim': 9}. Best is trial 11 with value: 0.05801684036850929.\n",
      "[I 2024-12-31 21:26:53,205] Trial 21 finished with value: 0.5810410976409912 and parameters: {'max_iter': 1021, 'epsilon': 0.01835575729938101, 'freq_dim': 5}. Best is trial 11 with value: 0.05801684036850929.\n",
      "[I 2024-12-31 21:27:21,607] Trial 22 finished with value: 0.33126431703567505 and parameters: {'max_iter': 1138, 'epsilon': 0.009933952425666432, 'freq_dim': 7}. Best is trial 11 with value: 0.05801684036850929.\n",
      "[I 2024-12-31 21:27:51,270] Trial 23 finished with value: 3.4885668754577637 and parameters: {'max_iter': 1201, 'epsilon': 0.10843690741489424, 'freq_dim': 8}. Best is trial 11 with value: 0.05801684036850929.\n",
      "[I 2024-12-31 21:28:25,634] Trial 24 finished with value: 7.063035011291504 and parameters: {'max_iter': 1427, 'epsilon': 0.22654700444582665, 'freq_dim': 12}. Best is trial 11 with value: 0.05801684036850929.\n",
      "[I 2024-12-31 21:28:42,546] Trial 25 finished with value: 7.079840660095215 and parameters: {'max_iter': 705, 'epsilon': 0.31598883670620825, 'freq_dim': 2}. Best is trial 11 with value: 0.05801684036850929.\n",
      "[I 2024-12-31 21:29:06,559] Trial 26 finished with value: 3.085477113723755 and parameters: {'max_iter': 979, 'epsilon': 0.10503101493199858, 'freq_dim': 5}. Best is trial 11 with value: 0.05801684036850929.\n",
      "[I 2024-12-31 21:29:21,256] Trial 27 finished with value: 12.408028602600098 and parameters: {'max_iter': 1524, 'epsilon': 0.596982389432058, 'freq_dim': 14}. Best is trial 11 with value: 0.05801684036850929.\n",
      "[I 2024-12-31 21:30:34,633] Trial 28 finished with value: 3.643711805343628 and parameters: {'max_iter': 2910, 'epsilon': 0.07340468261356616, 'freq_dim': 11}. Best is trial 11 with value: 0.05801684036850929.\n",
      "[I 2024-12-31 21:30:44,227] Trial 29 finished with value: 14.819473266601562 and parameters: {'max_iter': 404, 'epsilon': 0.8778300815424191, 'freq_dim': 7}. Best is trial 11 with value: 0.05801684036850929.\n",
      "[I 2024-12-31 21:31:12,079] Trial 30 finished with value: 10.784857749938965 and parameters: {'max_iter': 1098, 'epsilon': 0.4135806722852809, 'freq_dim': 9}. Best is trial 11 with value: 0.05801684036850929.\n",
      "[I 2024-12-31 21:31:38,011] Trial 31 finished with value: 0.2514333724975586 and parameters: {'max_iter': 952, 'epsilon': 0.008205274091376393, 'freq_dim': 7}. Best is trial 11 with value: 0.05801684036850929.\n",
      "[I 2024-12-31 21:31:57,483] Trial 32 finished with value: 4.49603796005249 and parameters: {'max_iter': 769, 'epsilon': 0.1817418853129499, 'freq_dim': 5}. Best is trial 11 with value: 0.05801684036850929.\n",
      "[I 2024-12-31 21:32:32,246] Trial 33 finished with value: 0.2522983253002167 and parameters: {'max_iter': 1436, 'epsilon': 0.006695296559137438, 'freq_dim': 3}. Best is trial 11 with value: 0.05801684036850929.\n",
      "[I 2024-12-31 21:33:07,274] Trial 34 finished with value: 2.850381374359131 and parameters: {'max_iter': 1460, 'epsilon': 0.07942281030559879, 'freq_dim': 2}. Best is trial 11 with value: 0.05801684036850929.\n",
      "[I 2024-12-31 21:33:26,846] Trial 35 finished with value: 4.2679123878479 and parameters: {'max_iter': 818, 'epsilon': 0.1628312396902948, 'freq_dim': 3}. Best is trial 11 with value: 0.05801684036850929.\n",
      "[I 2024-12-31 21:34:03,828] Trial 36 finished with value: 8.412187576293945 and parameters: {'max_iter': 1641, 'epsilon': 0.2652224225439624, 'freq_dim': 16}. Best is trial 11 with value: 0.05801684036850929.\n",
      "[I 2024-12-31 21:35:03,286] Trial 37 finished with value: 2.8406426906585693 and parameters: {'max_iter': 2439, 'epsilon': 0.061291462712226415, 'freq_dim': 4}. Best is trial 11 with value: 0.05801684036850929.\n",
      "[I 2024-12-31 21:35:48,430] Trial 38 finished with value: 7.1984477043151855 and parameters: {'max_iter': 1881, 'epsilon': 0.19635402401441768, 'freq_dim': 10}. Best is trial 11 with value: 0.05801684036850929.\n",
      "[I 2024-12-31 21:36:22,632] Trial 39 finished with value: 4.157183647155762 and parameters: {'max_iter': 1390, 'epsilon': 0.12312515847449872, 'freq_dim': 6}. Best is trial 11 with value: 0.05801684036850929.\n",
      "[I 2024-12-31 21:36:30,697] Trial 40 finished with value: 0.04233155399560928 and parameters: {'max_iter': 330, 'epsilon': 0.0023444710459838407, 'freq_dim': 14}. Best is trial 40 with value: 0.04233155399560928.\n",
      "[I 2024-12-31 21:36:35,760] Trial 41 finished with value: 0.8364517688751221 and parameters: {'max_iter': 208, 'epsilon': 0.05842037253325996, 'freq_dim': 13}. Best is trial 40 with value: 0.04233155399560928.\n",
      "[I 2024-12-31 21:36:43,592] Trial 42 finished with value: 0.07482103258371353 and parameters: {'max_iter': 314, 'epsilon': 0.0042632701433136565, 'freq_dim': 16}. Best is trial 40 with value: 0.04233155399560928.\n",
      "[I 2024-12-31 21:36:44,280] Trial 43 finished with value: 0.3325467109680176 and parameters: {'max_iter': 26, 'epsilon': 0.06650933546575488, 'freq_dim': 17}. Best is trial 40 with value: 0.04233155399560928.\n",
      "[I 2024-12-31 21:36:51,361] Trial 44 finished with value: 2.0763251781463623 and parameters: {'max_iter': 293, 'epsilon': 0.12754770335252646, 'freq_dim': 20}. Best is trial 40 with value: 0.04233155399560928.\n",
      "[I 2024-12-31 21:37:06,733] Trial 45 finished with value: 0.030781064182519913 and parameters: {'max_iter': 584, 'epsilon': 0.001293808549534169, 'freq_dim': 15}. Best is trial 45 with value: 0.030781064182519913.\n",
      "[I 2024-12-31 21:37:22,070] Trial 46 finished with value: 1.3524446487426758 and parameters: {'max_iter': 553, 'epsilon': 0.05902555932579105, 'freq_dim': 15}. Best is trial 45 with value: 0.030781064182519913.\n",
      "[I 2024-12-31 21:37:33,489] Trial 47 finished with value: 9.42343807220459 and parameters: {'max_iter': 308, 'epsilon': 0.6441733511031363, 'freq_dim': 17}. Best is trial 45 with value: 0.030781064182519913.\n",
      "[I 2024-12-31 21:37:33,980] Trial 48 finished with value: 0.4457888603210449 and parameters: {'max_iter': 10, 'epsilon': 0.15761020764276035, 'freq_dim': 15}. Best is trial 45 with value: 0.030781064182519913.\n",
      "[I 2024-12-31 21:37:47,248] Trial 49 finished with value: 5.565375804901123 and parameters: {'max_iter': 457, 'epsilon': 0.29621534909549496, 'freq_dim': 14}. Best is trial 45 with value: 0.030781064182519913.\n",
      "\n",
      "Best params::\n",
      "---------------\n",
      "{'max_iter': 584, 'epsilon': 0.001293808549534169, 'freq_dim': 15}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# DO NOT CHANGE\n",
    "\n",
    "def objective(trial, attack, x):\n",
    "    new_params = {\n",
    "        \"max_iter\": trial.suggest_int('max_iter',  10, 3000),\n",
    "        \"epsilon\": trial.suggest_float('epsilon', 1e-6, 1.0),\n",
    "        \"freq_dim\": trial.suggest_int('freq_dim', 1, 20),\n",
    "        \"stride\": 1,\n",
    "        \"batch_size\": 1,\n",
    "        \"verbose\": False\n",
    "    }\n",
    "\n",
    "    attack.set_params(**new_params)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        results = attack.generate(x = x)\n",
    "        \n",
    "    l2_norm = torch.norm(img_tensor - results, p=2).float()\n",
    "\n",
    "    return l2_norm\n",
    "\n",
    "study = optuna.create_study()\n",
    "study.optimize(\n",
    "    lambda trial: objective(trial, attack=attack, x=img_tensor.numpy()), n_trials=50, show_progress_bar=True\n",
    ");\n",
    "\n",
    "print(f\"\\nBest params::\\n---------------\\n{study.best_params}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "810357e2",
   "metadata": {},
   "source": [
    "That's quite the improvement over the default values for our `L2` metric! This metric is a little arbitrary as the attack technically already does this. Let's do something more useful. \n",
    "\n",
    "## Optimize 2 Values\n",
    "\n",
    "Here we add another metric that is more realistic - the number of queries, `num_queries`, we send the model. First we need to add logging functionality to our attack, which we will do in the predict function. Then we can simply return another value from the `objective` function and update the `study.optimize` call to provide a list of `directions`.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "94234769",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT CHANGE\n",
    "\n",
    "class ModelWrapper: \n",
    "    def __init__(self):\n",
    "        self.__reset__()\n",
    "    \n",
    "    def predict(self, x):\n",
    "        torch_tensor = torch.from_numpy(x).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            output = target_model(torch_tensor)        \n",
    "        probs = torch.softmax(output, dim=1).cpu().numpy()\n",
    "        \n",
    "        self.num_queries += 1\n",
    "        \n",
    "        return probs\n",
    "    \n",
    "    def __reset__(self):\n",
    "        self.num_queries = 0\n",
    "\n",
    "model_wrapper = ModelWrapper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9790c661",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT CHANGE\n",
    "\n",
    "classifier = BlackBoxClassifierNeuralNetwork(\n",
    "    predict_fn = lambda x:model_wrapper.predict(x),\n",
    "    nb_classes = len(labels),\n",
    "    input_shape = img_tensor[0].shape\n",
    ")\n",
    "\n",
    "attack = SimBA(classifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6d9437e",
   "metadata": {},
   "source": [
    "We set `num_queries = 0` using the `__reset__` method and run the attack, returning both `l2_norm` and `num_queries` . Then update the `optimize` call to include directions for _both_ return values, and Optuna will take care of the rest!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "021846c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT CHANGE\n",
    "\n",
    "def objective(trial, attack, x):\n",
    "    model_wrapper.__reset__()\n",
    "    new_params = {\n",
    "        \"max_iter\": trial.suggest_int('max_iter',  10, 3000),\n",
    "        \"epsilon\": trial.suggest_float('epsilon', 1e-6, 1.0),\n",
    "        \"freq_dim\": trial.suggest_int('freq_dim', 1, 20),\n",
    "        \"stride\": 1,\n",
    "        \"batch_size\": 1,\n",
    "        \"verbose\": False\n",
    "    }\n",
    "\n",
    "    attack.set_params(**new_params)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        results = attack.generate(x = x)\n",
    "    l2_norm = torch.norm(img_tensor - results, p=2)\n",
    "    \n",
    "    num_queries = model_wrapper.num_queries\n",
    "    \n",
    "    return l2_norm, num_queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "51b4cda1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-31 21:42:55,504] A new study created in memory with name: no-name-ace0f442-7ff2-4ccb-b46d-e8075a05a478\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ddb117468b8743db996fe1af2f02a8bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2024-12-31 21:43:42,903] Trial 0 finished with values: [4.6565680503845215, 3321.0] and parameters: {'max_iter': 1660, 'epsilon': 0.1283139438734348, 'freq_dim': 15}.\n",
      "[I 2024-12-31 21:43:48,074] Trial 1 finished with values: [4.1816253662109375, 279.0] and parameters: {'max_iter': 139, 'epsilon': 0.37105946432716275, 'freq_dim': 4}.\n",
      "[I 2024-12-31 21:43:49,799] Trial 2 finished with values: [5.026910781860352, 115.0] and parameters: {'max_iter': 57, 'epsilon': 0.6971075782017839, 'freq_dim': 5}.\n",
      "[I 2024-12-31 21:44:05,927] Trial 3 finished with values: [8.903767585754395, 1167.0] and parameters: {'max_iter': 583, 'epsilon': 0.41926237482278705, 'freq_dim': 6}.\n",
      "[I 2024-12-31 21:44:25,118] Trial 4 finished with values: [12.294295310974121, 1515.0] and parameters: {'max_iter': 1935, 'epsilon': 0.5658916097628848, 'freq_dim': 20}.\n",
      "[I 2024-12-31 21:45:04,193] Trial 5 finished with values: [3.0220212936401367, 2983.0] and parameters: {'max_iter': 1491, 'epsilon': 0.08400994451970752, 'freq_dim': 2}.\n",
      "[I 2024-12-31 21:45:17,083] Trial 6 finished with values: [16.817190170288086, 1025.0] and parameters: {'max_iter': 2857, 'epsilon': 0.92157620369663, 'freq_dim': 5}.\n",
      "[I 2024-12-31 21:45:30,707] Trial 7 finished with values: [3.6616060733795166, 1037.0] and parameters: {'max_iter': 518, 'epsilon': 0.1722276741194416, 'freq_dim': 9}.\n",
      "[I 2024-12-31 21:45:53,010] Trial 8 finished with values: [11.908201217651367, 1715.0] and parameters: {'max_iter': 1376, 'epsilon': 0.5086934149001796, 'freq_dim': 9}.\n",
      "[I 2024-12-31 21:46:02,015] Trial 9 finished with values: [4.509127616882324, 611.0] and parameters: {'max_iter': 305, 'epsilon': 0.27141791582904956, 'freq_dim': 10}.\n",
      "[I 2024-12-31 21:46:15,450] Trial 10 finished with values: [16.30217933654785, 1059.0] and parameters: {'max_iter': 1542, 'epsilon': 0.8841108056362701, 'freq_dim': 13}.\n",
      "[I 2024-12-31 21:46:24,072] Trial 11 finished with values: [10.298924446105957, 667.0] and parameters: {'max_iter': 333, 'epsilon': 0.6593219834519324, 'freq_dim': 8}.\n",
      "[I 2024-12-31 21:46:41,063] Trial 12 finished with values: [5.483731746673584, 1367.0] and parameters: {'max_iter': 683, 'epsilon': 0.23978703437782142, 'freq_dim': 19}.\n",
      "[I 2024-12-31 21:47:13,616] Trial 13 finished with values: [10.075843811035156, 2379.0] and parameters: {'max_iter': 1461, 'epsilon': 0.3640552845980229, 'freq_dim': 3}.\n",
      "[I 2024-12-31 21:47:21,824] Trial 14 finished with values: [5.2942795753479, 693.0] and parameters: {'max_iter': 346, 'epsilon': 0.31810265462797654, 'freq_dim': 19}.\n",
      "[I 2024-12-31 21:48:09,005] Trial 15 finished with values: [0.9485044479370117, 3965.0] and parameters: {'max_iter': 1982, 'epsilon': 0.02161836421405685, 'freq_dim': 3}.\n",
      "[I 2024-12-31 21:48:20,802] Trial 16 finished with values: [6.531972885131836, 999.0] and parameters: {'max_iter': 499, 'epsilon': 0.32497811959299083, 'freq_dim': 6}.\n",
      "[I 2024-12-31 21:48:22,787] Trial 17 finished with values: [5.0798749923706055, 155.0] and parameters: {'max_iter': 77, 'epsilon': 0.6206056978379382, 'freq_dim': 17}.\n",
      "[I 2024-12-31 21:49:10,178] Trial 18 finished with values: [5.502902984619141, 4003.0] and parameters: {'max_iter': 2001, 'epsilon': 0.140181545483445, 'freq_dim': 5}.\n",
      "[I 2024-12-31 21:49:22,505] Trial 19 finished with values: [16.600862503051758, 1071.0] and parameters: {'max_iter': 929, 'epsilon': 0.9083593639288147, 'freq_dim': 13}.\n",
      "[I 2024-12-31 21:49:34,787] Trial 20 finished with values: [13.923166275024414, 1043.0] and parameters: {'max_iter': 2933, 'epsilon': 0.706842142558149, 'freq_dim': 9}.\n",
      "[I 2024-12-31 21:49:55,166] Trial 21 finished with values: [11.702462196350098, 1753.0] and parameters: {'max_iter': 2622, 'epsilon': 0.4867588074500189, 'freq_dim': 17}.\n",
      "[I 2024-12-31 21:50:02,404] Trial 22 finished with values: [9.442113876342773, 605.0] and parameters: {'max_iter': 302, 'epsilon': 0.619905645194733, 'freq_dim': 1}.\n",
      "[I 2024-12-31 21:50:35,333] Trial 23 finished with values: [8.68498420715332, 2837.0] and parameters: {'max_iter': 1507, 'epsilon': 0.277573529025178, 'freq_dim': 19}.\n",
      "[I 2024-12-31 21:50:50,397] Trial 24 finished with values: [9.403903007507324, 1277.0] and parameters: {'max_iter': 638, 'epsilon': 0.4467933342984454, 'freq_dim': 20}.\n",
      "[I 2024-12-31 21:51:02,365] Trial 25 finished with values: [13.963639259338379, 1025.0] and parameters: {'max_iter': 2048, 'epsilon': 0.7584014233778418, 'freq_dim': 6}.\n",
      "[I 2024-12-31 21:51:10,146] Trial 26 finished with values: [7.409243106842041, 663.0] and parameters: {'max_iter': 331, 'epsilon': 0.465815350892752, 'freq_dim': 1}.\n",
      "[I 2024-12-31 21:51:25,177] Trial 27 finished with values: [11.638290405273438, 1297.0] and parameters: {'max_iter': 648, 'epsilon': 0.5790269778393917, 'freq_dim': 20}.\n",
      "[I 2024-12-31 21:52:00,443] Trial 28 finished with values: [0.4826166033744812, 2945.0] and parameters: {'max_iter': 1472, 'epsilon': 0.012687256665435007, 'freq_dim': 5}.\n",
      "[I 2024-12-31 21:52:46,724] Trial 29 finished with values: [6.612401962280273, 3907.0] and parameters: {'max_iter': 2560, 'epsilon': 0.17305458141838953, 'freq_dim': 16}.\n",
      "[I 2024-12-31 21:52:58,522] Trial 30 finished with values: [14.420243263244629, 1015.0] and parameters: {'max_iter': 1669, 'epsilon': 0.7589610926235955, 'freq_dim': 10}.\n",
      "[I 2024-12-31 21:53:20,443] Trial 31 finished with values: [10.41293716430664, 1885.0] and parameters: {'max_iter': 2227, 'epsilon': 0.4025876023730172, 'freq_dim': 16}.\n",
      "[I 2024-12-31 21:53:31,646] Trial 32 finished with values: [14.811464309692383, 967.0] and parameters: {'max_iter': 1429, 'epsilon': 0.7985808954477224, 'freq_dim': 11}.\n",
      "[I 2024-12-31 21:53:47,932] Trial 33 finished with values: [12.693819999694824, 1399.0] and parameters: {'max_iter': 819, 'epsilon': 0.5861467156079778, 'freq_dim': 18}.\n",
      "[I 2024-12-31 21:54:08,927] Trial 34 finished with values: [13.770355224609375, 1767.0] and parameters: {'max_iter': 2640, 'epsilon': 0.6121673699158708, 'freq_dim': 6}.\n",
      "[I 2024-12-31 21:54:22,160] Trial 35 finished with values: [13.730720520019531, 1131.0] and parameters: {'max_iter': 1030, 'epsilon': 0.6952824404006019, 'freq_dim': 13}.\n",
      "[I 2024-12-31 21:55:20,302] Trial 36 finished with values: [5.323726177215576, 4937.0] and parameters: {'max_iter': 2468, 'epsilon': 0.12133903558780758, 'freq_dim': 7}.\n",
      "[I 2024-12-31 21:55:47,943] Trial 37 finished with values: [8.955581665039062, 2345.0] and parameters: {'max_iter': 1566, 'epsilon': 0.3086301490346997, 'freq_dim': 20}.\n",
      "[I 2024-12-31 21:56:04,338] Trial 38 finished with values: [12.11831283569336, 1405.0] and parameters: {'max_iter': 982, 'epsilon': 0.564406189929323, 'freq_dim': 4}.\n",
      "[I 2024-12-31 21:56:18,568] Trial 39 finished with values: [13.657928466796875, 1227.0] and parameters: {'max_iter': 613, 'epsilon': 0.6778317956281416, 'freq_dim': 6}.\n",
      "[I 2024-12-31 21:56:30,053] Trial 40 finished with values: [15.953620910644531, 979.0] and parameters: {'max_iter': 1350, 'epsilon': 0.8808922305972875, 'freq_dim': 11}.\n",
      "[I 2024-12-31 21:57:07,568] Trial 41 finished with values: [8.452287673950195, 3213.0] and parameters: {'max_iter': 1997, 'epsilon': 0.2535815983227858, 'freq_dim': 5}.\n",
      "[I 2024-12-31 21:57:12,053] Trial 42 finished with values: [6.685277462005615, 369.0] and parameters: {'max_iter': 184, 'epsilon': 0.5775200241501519, 'freq_dim': 20}.\n",
      "[I 2024-12-31 21:57:17,444] Trial 43 finished with values: [9.025280952453613, 425.0] and parameters: {'max_iter': 212, 'epsilon': 0.6901811415320794, 'freq_dim': 9}.\n",
      "[I 2024-12-31 21:57:27,771] Trial 44 finished with values: [16.83147621154785, 857.0] and parameters: {'max_iter': 1113, 'epsilon': 0.9468449061553099, 'freq_dim': 9}.\n",
      "[I 2024-12-31 21:57:42,630] Trial 45 finished with values: [12.080690383911133, 1253.0] and parameters: {'max_iter': 1882, 'epsilon': 0.5514059898680231, 'freq_dim': 15}.\n",
      "[I 2024-12-31 21:57:45,662] Trial 46 finished with values: [2.9180448055267334, 247.0] and parameters: {'max_iter': 123, 'epsilon': 0.2721092669007659, 'freq_dim': 15}.\n",
      "[I 2024-12-31 21:58:09,162] Trial 47 finished with values: [9.625024795532227, 2013.0] and parameters: {'max_iter': 2005, 'epsilon': 0.3677536792143852, 'freq_dim': 4}.\n",
      "[I 2024-12-31 21:58:40,224] Trial 48 finished with values: [9.907953262329102, 2603.0] and parameters: {'max_iter': 2992, 'epsilon': 0.34145097891948917, 'freq_dim': 9}.\n",
      "[I 2024-12-31 21:58:51,802] Trial 49 finished with values: [15.956101417541504, 991.0] and parameters: {'max_iter': 852, 'epsilon': 0.8947746965965394, 'freq_dim': 1}.\n",
      "[I 2024-12-31 21:59:36,271] Trial 50 finished with values: [3.331920862197876, 3689.0] and parameters: {'max_iter': 1844, 'epsilon': 0.08400994451970752, 'freq_dim': 2}.\n",
      "[I 2024-12-31 22:00:11,974] Trial 51 finished with values: [7.858279228210449, 3031.0] and parameters: {'max_iter': 2933, 'epsilon': 0.23978703437782142, 'freq_dim': 17}.\n",
      "[I 2024-12-31 22:00:38,310] Trial 52 finished with values: [8.889809608459473, 2235.0] and parameters: {'max_iter': 1117, 'epsilon': 0.31810265462797654, 'freq_dim': 19}.\n",
      "[I 2024-12-31 22:00:49,989] Trial 53 finished with values: [5.414903163909912, 999.0] and parameters: {'max_iter': 499, 'epsilon': 0.2721092669007659, 'freq_dim': 14}.\n",
      "[I 2024-12-31 22:00:57,142] Trial 54 finished with values: [10.070975303649902, 605.0] and parameters: {'max_iter': 302, 'epsilon': 0.6597717138452371, 'freq_dim': 10}.\n",
      "[I 2024-12-31 22:01:11,427] Trial 55 finished with values: [13.957395553588867, 1227.0] and parameters: {'max_iter': 613, 'epsilon': 0.6778317956281416, 'freq_dim': 2}.\n",
      "[I 2024-12-31 22:01:50,599] Trial 56 finished with values: [4.622857093811035, 3321.0] and parameters: {'max_iter': 1660, 'epsilon': 0.1283139438734348, 'freq_dim': 15}.\n",
      "[I 2024-12-31 22:01:58,427] Trial 57 finished with values: [9.142080307006836, 663.0] and parameters: {'max_iter': 331, 'epsilon': 0.6206056978379382, 'freq_dim': 17}.\n",
      "[I 2024-12-31 22:02:01,735] Trial 58 finished with values: [6.410419940948486, 279.0] and parameters: {'max_iter': 139, 'epsilon': 0.564406189929323, 'freq_dim': 4}.\n",
      "[I 2024-12-31 22:02:28,020] Trial 59 finished with values: [2.615124225616455, 2153.0] and parameters: {'max_iter': 1076, 'epsilon': 0.08400994451970752, 'freq_dim': 2}.\n",
      "[I 2024-12-31 22:02:44,396] Trial 60 finished with values: [12.006953239440918, 1407.0] and parameters: {'max_iter': 2001, 'epsilon': 0.5790269778393917, 'freq_dim': 20}.\n",
      "[I 2024-12-31 22:02:46,162] Trial 61 finished with values: [3.911639451980591, 155.0] and parameters: {'max_iter': 77, 'epsilon': 0.5136237315858515, 'freq_dim': 13}.\n",
      "[I 2024-12-31 22:03:00,661] Trial 62 finished with values: [13.495975494384766, 1239.0] and parameters: {'max_iter': 1429, 'epsilon': 0.6593219834519324, 'freq_dim': 11}.\n",
      "[I 2024-12-31 22:03:43,068] Trial 63 finished with values: [1.1942334175109863, 3545.0] and parameters: {'max_iter': 1772, 'epsilon': 0.02890501221622267, 'freq_dim': 16}.\n",
      "[I 2024-12-31 22:03:46,006] Trial 64 finished with values: [1.4880971908569336, 239.0] and parameters: {'max_iter': 119, 'epsilon': 0.1381664840118771, 'freq_dim': 1}.\n",
      "[I 2024-12-31 22:03:58,834] Trial 65 finished with values: [3.7417380809783936, 1037.0] and parameters: {'max_iter': 518, 'epsilon': 0.1722276741194416, 'freq_dim': 9}.\n",
      "[I 2024-12-31 22:04:11,689] Trial 66 finished with values: [15.663045883178711, 1087.0] and parameters: {'max_iter': 852, 'epsilon': 0.7812026308748616, 'freq_dim': 3}.\n",
      "[I 2024-12-31 22:04:19,739] Trial 67 finished with values: [5.213318347930908, 667.0] and parameters: {'max_iter': 333, 'epsilon': 0.30099127056312563, 'freq_dim': 8}.\n",
      "[I 2024-12-31 22:04:30,161] Trial 68 finished with values: [13.854903221130371, 899.0] and parameters: {'max_iter': 1566, 'epsilon': 0.8235890298259173, 'freq_dim': 20}.\n",
      "[I 2024-12-31 22:04:37,380] Trial 69 finished with values: [4.45158052444458, 611.0] and parameters: {'max_iter': 305, 'epsilon': 0.27141791582904956, 'freq_dim': 13}.\n",
      "[I 2024-12-31 22:05:07,739] Trial 70 finished with values: [9.705910682678223, 2583.0] and parameters: {'max_iter': 1491, 'epsilon': 0.32497811959299083, 'freq_dim': 9}.\n",
      "[I 2024-12-31 22:05:09,615] Trial 71 finished with values: [3.9842922687530518, 157.0] and parameters: {'max_iter': 78, 'epsilon': 0.4867588074500189, 'freq_dim': 19}.\n",
      "[I 2024-12-31 22:06:19,724] Trial 72 finished with values: [4.396796226501465, 5985.0] and parameters: {'max_iter': 2992, 'epsilon': 0.09006895721746037, 'freq_dim': 9}.\n",
      "[I 2024-12-31 22:06:31,661] Trial 73 finished with values: [5.138027667999268, 1007.0] and parameters: {'max_iter': 503, 'epsilon': 0.25011564244752477, 'freq_dim': 9}.\n",
      "[I 2024-12-31 22:06:53,802] Trial 74 finished with values: [6.269509792327881, 1897.0] and parameters: {'max_iter': 948, 'epsilon': 0.23284396439278798, 'freq_dim': 17}.\n",
      "[I 2024-12-31 22:07:11,365] Trial 75 finished with values: [12.573488235473633, 1513.0] and parameters: {'max_iter': 1180, 'epsilon': 0.5775200241501519, 'freq_dim': 6}.\n",
      "[I 2024-12-31 22:08:14,501] Trial 76 finished with values: [4.182065010070801, 5281.0] and parameters: {'max_iter': 2640, 'epsilon': 0.09074315566644625, 'freq_dim': 17}.\n",
      "[I 2024-12-31 22:08:25,724] Trial 77 finished with values: [12.688817024230957, 957.0] and parameters: {'max_iter': 478, 'epsilon': 0.6901811415320794, 'freq_dim': 9}.\n",
      "[I 2024-12-31 22:08:57,834] Trial 78 finished with values: [9.091085433959961, 2753.0] and parameters: {'max_iter': 1376, 'epsilon': 0.30153234012700275, 'freq_dim': 9}.\n",
      "[I 2024-12-31 22:09:33,380] Trial 79 finished with values: [0.4821159243583679, 2945.0] and parameters: {'max_iter': 1472, 'epsilon': 0.012687256665435007, 'freq_dim': 5}.\n",
      "[I 2024-12-31 22:09:53,594] Trial 80 finished with values: [11.651744842529297, 1737.0] and parameters: {'max_iter': 929, 'epsilon': 0.4867588074500189, 'freq_dim': 17}.\n",
      "[I 2024-12-31 22:09:57,012] Trial 81 finished with values: [5.442124366760254, 279.0] and parameters: {'max_iter': 139, 'epsilon': 0.4867588074500189, 'freq_dim': 4}.\n",
      "[I 2024-12-31 22:10:10,974] Trial 82 finished with values: [13.252196311950684, 1185.0] and parameters: {'max_iter': 2930, 'epsilon': 0.6593219834519324, 'freq_dim': 14}.\n",
      "[I 2024-12-31 22:10:31,360] Trial 83 finished with values: [2.3507769107818604, 1705.0] and parameters: {'max_iter': 852, 'epsilon': 0.08400994451970752, 'freq_dim': 2}.\n",
      "[I 2024-12-31 22:10:55,202] Trial 84 finished with values: [7.56100606918335, 2021.0] and parameters: {'max_iter': 1010, 'epsilon': 0.277573529025178, 'freq_dim': 19}.\n",
      "[I 2024-12-31 22:11:08,928] Trial 85 finished with values: [11.04651165008545, 1167.0] and parameters: {'max_iter': 583, 'epsilon': 0.5572230028317889, 'freq_dim': 16}.\n",
      "[I 2024-12-31 22:11:25,192] Trial 86 finished with values: [12.493675231933594, 1377.0] and parameters: {'max_iter': 2256, 'epsilon': 0.5775200241501519, 'freq_dim': 20}.\n",
      "[I 2024-12-31 22:11:56,896] Trial 87 finished with values: [9.391685485839844, 2703.0] and parameters: {'max_iter': 2091, 'epsilon': 0.3086301490346997, 'freq_dim': 20}.\n",
      "[I 2024-12-31 22:12:08,708] Trial 88 finished with values: [2.591092109680176, 987.0] and parameters: {'max_iter': 493, 'epsilon': 0.12133903558780758, 'freq_dim': 1}.\n",
      "[I 2024-12-31 22:12:27,349] Trial 89 finished with values: [12.452491760253906, 1599.0] and parameters: {'max_iter': 2787, 'epsilon': 0.5514059898680231, 'freq_dim': 3}.\n",
      "[I 2024-12-31 22:12:44,615] Trial 90 finished with values: [7.905152797698975, 1427.0] and parameters: {'max_iter': 713, 'epsilon': 0.34145097891948917, 'freq_dim': 9}.\n",
      "[I 2024-12-31 22:13:06,208] Trial 91 finished with values: [10.411139488220215, 1829.0] and parameters: {'max_iter': 946, 'epsilon': 0.4074195920594842, 'freq_dim': 4}.\n",
      "[I 2024-12-31 22:13:27,896] Trial 92 finished with values: [10.358977317810059, 1855.0] and parameters: {'max_iter': 1472, 'epsilon': 0.4140285536673359, 'freq_dim': 3}.\n",
      "[I 2024-12-31 22:13:39,944] Trial 93 finished with values: [14.607831954956055, 1025.0] and parameters: {'max_iter': 2048, 'epsilon': 0.7584014233778418, 'freq_dim': 10}.\n",
      "[I 2024-12-31 22:14:17,417] Trial 94 finished with values: [0.15448898077011108, 3085.0] and parameters: {'max_iter': 1542, 'epsilon': 0.0039612940601021895, 'freq_dim': 11}.\n",
      "[I 2024-12-31 22:14:22,177] Trial 95 finished with values: [1.1610389947891235, 387.0] and parameters: {'max_iter': 193, 'epsilon': 0.08400994451970752, 'freq_dim': 20}.\n",
      "[I 2024-12-31 22:14:47,443] Trial 96 finished with values: [10.087081909179688, 2127.0] and parameters: {'max_iter': 2048, 'epsilon': 0.37105946432716275, 'freq_dim': 19}.\n",
      "[I 2024-12-31 22:14:59,066] Trial 97 finished with values: [15.980400085449219, 977.0] and parameters: {'max_iter': 1472, 'epsilon': 0.8457733133503842, 'freq_dim': 2}.\n",
      "[I 2024-12-31 22:15:19,635] Trial 98 finished with values: [12.059348106384277, 1727.0] and parameters: {'max_iter': 1566, 'epsilon': 0.5086934149001796, 'freq_dim': 8}.\n",
      "[I 2024-12-31 22:15:23,068] Trial 99 finished with values: [4.295313835144043, 279.0] and parameters: {'max_iter': 139, 'epsilon': 0.37105946432716275, 'freq_dim': 4}.\n"
     ]
    }
   ],
   "source": [
    "# DO NOT CHANGE\n",
    "\n",
    "study = optuna.create_study(directions=[\"minimize\", \"minimize\"])\n",
    "study.optimize(\n",
    "    lambda trial: objective(trial, attack=attack, x=img_tensor.numpy()), n_trials=100, show_progress_bar=True\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edd2cc4a",
   "metadata": {},
   "source": [
    "## Tiny Assessment (Optional Challenge)\n",
    "\n",
    ":::{exercise}\n",
    "Put it all together for a full assessment. We want to characterize the robustness of this model (or effectiveness of the attack) under different constraints for query budget.  Do the following.\n",
    "\n",
    "1. Rewrite the objective function so that it performs multiple trials (say 100), and computes the attack accuracy.\n",
    "2. Fix the query budget; optimize the remaining hyperparameters (`epsilon` and `freq_dim`) under the constrained query budget.\n",
    "3. Perform the optimization/estimation step for a range of query budgets (try 10, 50, 100, 200, 300, 400, 500, 1000)\n",
    "4. Visualize the results, showing the best attainable success rate of the attack against the query budget. Think through how you would report this to a data scientist.\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e254dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8eac52e",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "In this lab we optimized the optimizer! This is another favorite technique of ours - the framework defaults are _okay_, but they are by definition not the strongest possible attack. Each model is different; use Optuna to express that in your assessments. And don't forget to track which parameters work best against which targets!\n",
    "\n",
    "## What You Learned\n",
    "\n",
    "1. How to think about ML and ML security problems as optimizations.\n",
    "2. How to apply `Optuna` for hyperparameter optimization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "714679eb-482d-4a50-9d11-7a4968809510",
   "metadata": {},
   "source": [
    "**Move on to the [Inversion Module](../5_inversion/1_inversion_and_membership_inference.ipynb).**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7cdc19a-4bfc-447d-9d1c-76f91bb4a376",
   "metadata": {},
   "source": [
    "![DLI Logo](../assets/DLI_Header.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
