{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assessments Answer Key\n",
    "This answer key is configured such that you should be able to run the code here and see possible approaches to a working solution. For each topic, it will also link further resources, and go into more detail on certain code chunks. It is not meant to be edited. \n",
    "\n",
    "Use these answer keys as a guide as needed. Try to work use the context here to work toward an answer before reaching for the solution.\n",
    "\n",
    "**If you just want to see the answers, they're all tagged with \"SOLUTION\", CTRL+F your heart out.**\n",
    "\n",
    "## Setup\n",
    "The setup code must be run for the solutions to work properly. Review the breakdown of the setup code in the lab notebook for an explanation of each section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import spacy\n",
    "from alibi.datasets import load_cats\n",
    "from alibi.explainers import AnchorImage\n",
    "from IPython import display\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from transformers import AutoTokenizer, BertForSequenceClassification\n",
    "from textattack import Attack, Attacker\n",
    "from textattack.attack_recipes import DeepWordBugGao2018\n",
    "from textattack.datasets import Dataset\n",
    "from art.attacks.evasion import CarliniL2Method, HopSkipJump\n",
    "from art.estimators.classification import PyTorchClassifier, BlackBoxClassifier\n",
    "\n",
    "# put the model on a GPU if available, otherwise CPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "\n",
    "target_model = torch.hub.load('pytorch/vision:v0.10.0', \n",
    "                              'mobilenet_v2', \n",
    "                              weights='MobileNet_V2_Weights.DEFAULT', \n",
    "                              verbose=False)\n",
    "target_model.train()\n",
    "target_model.to(device);\n",
    "\n",
    "# Define the transforms for preprocessing\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize(256), \n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    )\n",
    "]);\n",
    "\n",
    "unnormalize = transforms.Normalize(\n",
    "   mean= [-m/s for m, s in zip([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])],\n",
    "   std= [1/s for s in [0.229, 0.224, 0.225]]\n",
    ")\n",
    "\n",
    "with open(\"../data/labels.txt\", 'r') as f:\n",
    "    labels = [label.strip() for label in f.readlines()]\n",
    "\n",
    "img = Image.open(\"../data/dog.jpg\")\n",
    "img_tensor = preprocess(img).unsqueeze(0)\n",
    "unnormed_img_tensor = unnormalize(img_tensor).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adversarial Robustness Toolbox (ART)\n",
    "- [ART Docs](https://adversarial-robustness-toolbox.readthedocs.io/en/latest/)\n",
    "\n",
    "### SOLUTION Exercise 1\n",
    "#### Troubleshooting\n",
    "_Help! I'm seeing..._\n",
    "- `ConnectionError`: make sure your local model is running! Run `python /dli/4_assessments/score.py` from a terminal.\n",
    "- `ValueError: pic should be 2/3 dimensional. Got 4 dimensions.`: Did you remember to `unnormalize` the tensor before passing it to the API? If yes, look at the shape of the unnormalized tensor. Take a look at the examples from prior labs. What information from the unnormalized tensor does the model expect?\n",
    "- \"uhhh it's not predicting a dog at all...\": Did you remember to `unnormalize` the tensor before passing it to the API?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import base64\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "\n",
    "img_hsj = Image.open(\"../data/dog.jpg\")\n",
    "img_tensor_hsj = preprocess(img_hsj).unsqueeze(0)\n",
    "\n",
    "# Convert PIL image to bytes\n",
    "buffer = BytesIO()\n",
    "img_hsj.save(buffer, format=\"JPEG\")\n",
    "image_bytes = buffer.getvalue()\n",
    "\n",
    "# Encode bytes using base64\n",
    "encoded_image = base64.urlsafe_b64encode(image_bytes).decode('utf-8')\n",
    "\n",
    "def send_encoded_image(encoded_image,url=\"http://127.0.0.1:2718/predict\"):\n",
    "    # Payload data for the POST request\n",
    "    data = {\n",
    "        'image': encoded_image\n",
    "    }\n",
    "\n",
    "    # Send the POST request\n",
    "    response = requests.post(url, json=data)\n",
    "\n",
    "    # Check the response status code\n",
    "    if response.status_code == 200:\n",
    "        # Request was successful\n",
    "        return response.json()\n",
    "    else:\n",
    "        # Request failed\n",
    "        print('Error:', response.text)\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You'll need to run the above to the solution to work!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(x):\n",
    "    # Convert numpy array into tensor\n",
    "    torch_tensor = torch.from_numpy(x).to(device)\n",
    "\n",
    "    # unnormalize the tensor and convert it to a PIL image\n",
    "    unnormed_img_hsj = unnormalize(torch_tensor).to(device)\n",
    "    img_hsj = transforms.functional.to_pil_image(unnormed_img_hsj[0])\n",
    "    \n",
    "    # Convert PIL image to bytes\n",
    "    buffer = BytesIO()\n",
    "    img_hsj.save(buffer, format=\"JPEG\")\n",
    "    image_bytes = buffer.getvalue()\n",
    "    encoded_image = base64.urlsafe_b64encode(image_bytes).decode('utf-8')\n",
    "\n",
    "    # Send the encoded image to the model endpoint\n",
    "    resp = send_encoded_image(encoded_image)\n",
    "\n",
    "    import sys\n",
    "    amax = np.argmax(resp[\"probs\"])\n",
    "    sys.stdout.write(f'{resp[\"label\"]}\\t{resp[\"probs\"][0][amax]}\\r')\n",
    "    return resp['probs']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SOLUTION: Exercise 2\n",
    "The important context for this exercise is that, with `nb_classes=2`, ART \"expects\" the return value of the `predict` function to be formatted `[p(original class), p(anything else)]`. \n",
    "\n",
    "With that, think carefully about how you might need to modify the return value of the predict function such that ART can still do the following...\n",
    "- Quickly identify that it has crossed the decision boundary\n",
    "- Recognize that it is \"moving\" in the right direction\n",
    "\n",
    "In HSJ, remember that ART is attempting to find the optimal image that crosses the decision boundary while still being recognizable as the original image, which is why it doesn't immediately terminate when we've achieved a single misclassification.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(x):\n",
    "    # Convert numpy array into tensor\n",
    "    torch_tensor = torch.from_numpy(x).to(device)\n",
    "\n",
    "    # unnormalize the tensor and convert it to a PIL image\n",
    "    unnormed_img_hsj = unnormalize(torch_tensor).to(device)\n",
    "    img_hsj = transforms.functional.to_pil_image(unnormed_img_hsj[0])\n",
    "    \n",
    "    # Convert PIL image to bytes\n",
    "    buffer = BytesIO()\n",
    "    img_hsj.save(buffer, format=\"JPEG\")\n",
    "    image_bytes = buffer.getvalue()\n",
    "    encoded_image = base64.urlsafe_b64encode(image_bytes).decode('utf-8')\n",
    "\n",
    "    # Send the encoded image to the model endpoint\n",
    "    resp = send_encoded_image(encoded_image)\n",
    "\n",
    "    import sys\n",
    "    sys.stdout.write(f'{resp[\"label\"]}\\t{resp[\"prob\"]}\\r')\n",
    "    if resp['label'] == original_label:\n",
    "        return [resp['prob'], 0]\n",
    "    else:\n",
    "        return [0, resp['prob']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The important part is this chunk:\n",
    "\n",
    "```python\n",
    "if resp['label'] == original_label:\n",
    "    return [resp['prob'], 0]\n",
    "else:\n",
    "    return [0, resp['prob']]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Help me understand..._\n",
    "- **What is this even doing?**: Remember that ART expects the format of the return value of `predict` to be `[p(original class), p(anything else)]`. If we generate an adversarial example that gets us over the decision boundary, we want to _force_ the probability of the `German shepherd` class to go to zero, and vice versa.\n",
    "- **Why can't we do this instead?**\n",
    "\n",
    "```python\n",
    "if resp[\"label\"] == curLabel:\n",
    "    probs = [resp['prob'],1-resp['prob']]\n",
    "else:\n",
    "    probs = [1-resp['prob'],resp['prob']]\n",
    "```\n",
    "\n",
    "(even if you aren't asking yourself this, try it, and see if you can work out why it doesn't work)\n",
    "\n",
    "Just because we can crossed the decision boundary and therefore found an image where `p(class X) > p(German shepherd)` doesn't mean that `p(class X) > (1 - p(class X))`. `p(class X)` can be very tiny and still be greater than `p(German shepherd)`, but if we use the above approach and `p(class X) = 0.04`, for example, we'd be telling ART that `p(German shepherd) = 0.96` and leave ART feeling like it just can't find any image that crosses the decision boundary. We want ART to be stoked about crossing the decision boundary! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just for fun, after you finish this section, go look at the server you're running in the terminal. That's a lot of requests! It's not exactly a covert attack."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alibi\n",
    "There were no exercises for the TextAttack portion, so we'll skip right to the Alibi section.\n",
    "\n",
    "### Resources\n",
    "- [Alibi AnchorText Docs](https://docs.seldon.io/projects/alibi/en/latest/api/alibi.explainers.anchors.anchor_text.html)\n",
    "\n",
    "### Setup \n",
    "You'll need to run this for the exercise solution to work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from alibi.utils import spacy_model\n",
    "\n",
    "model = 'en_core_web_md'\n",
    "spacy_model(model=model)\n",
    "nlp = spacy.load(model)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"textattack/bert-base-uncased-yelp-polarity\")\n",
    "model = BertForSequenceClassification.from_pretrained(\"textattack/bert-base-uncased-yelp-polarity\")\n",
    "\n",
    "def predict(x):\n",
    "    inputs = tokenizer(x, return_tensors=\"pt\", padding=True)\n",
    "    with torch.no_grad():\n",
    "        output = model(**inputs)\n",
    "    return output.logits.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SOLUTION: Exercise 3\n",
    "1. Create a list that contains more than one text sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = [\n",
    "    'My dear aunt Sally loved this movie',\n",
    "    'This film was strange yet oddly charming',\n",
    "    'A heartwarming story that had me in tears by the end',\n",
    "    'The special effects were cool, but the story was lacking',\n",
    "    'Yawn. I could not stay awake.',\n",
    "    'I would watch this again and again!'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Make a simple modification to the `explainer` to deal with 0 or 1 (discrete) outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from alibi.explainers import AnchorText\n",
    "explainer = AnchorText(\n",
    "    predictor=predict,\n",
    "    sampling_strategy='unknown',\n",
    "    nlp=nlp,\n",
    "    use_proba=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_NOTE: the above might throw a warning, it's safe to ignore_\n",
    "\n",
    "_Help me understand_...\n",
    "- **What does the `use_proba` argument change?**\n",
    "\n",
    "From the docs... \"`use_proba` : `bool` - whether to sample according to the predicted words distribution. If set to `False`, the `top_n` words are sampled uniformly at random.\" In other words, when we set this to `False`, our `explainer` no longer expects the `predict` function to return logits.\n",
    "\n",
    "Let's make sure this works!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in text:\n",
    "    pred = predict(text)\n",
    "    predicted_class_id = pred.argmax().item()\n",
    "    explanation = explainer.explain(t, threshold=0.95)\n",
    "    print(f\"\\n\\n\\nText: {t}\")\n",
    "    print(f\"Anchor: {explanation.anchor}\")\n",
    "    print(f'Precision: {explanation.precision:.2f}\\n')\n",
    "    \n",
    "    print(f\"Examples where anchor applies and model predicts: {predicted_class_id}\\n---------------\\n\")\n",
    "    print('\\n'.join([x for x in explanation.raw['examples'][-1]['covered_true']])) \n",
    "    print(f\"\\nExamples where anchor applies and model predicts: 0\\n---------------\\n\")\n",
    "    print('\\n'.join([x for x in explanation.raw['examples'][-1]['covered_false']]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
